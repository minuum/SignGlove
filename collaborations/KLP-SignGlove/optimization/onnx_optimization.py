"""
ONNX ìµœì í™” ë‹¨ë… ì‹¤í–‰
"""

import torch
import torch.nn as nn
import time
import os
import json
import numpy as np
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from models.deep_learning import DeepLearningPipeline
from training.dataset import KSLCsvDataset
from torch.utils.data import DataLoader, Subset

def run_onnx_optimization():
    """ONNX ìµœì í™” ì‹¤í–‰"""
    print("ğŸš€ ONNX ìµœì í™” ì‹œì‘")
    
    # ëª¨ë¸ ì„¤ì •
    model_config = {
        'input_features': 8,
        'sequence_length': 20,
        'num_classes': 5,
        'hidden_dim': 128,
        'num_layers': 2,
        'dropout': 0.3
    }
    
    device = torch.device('cpu')  # ONNXëŠ” CPUì—ì„œ ì‹¤í–‰
    
    # ëª¨ë¸ ë¡œë“œ
    model = DeepLearningPipeline(**model_config)
    model_path = 'best_dl_model.pth'
    
    if os.path.exists(model_path):
        state_dict = torch.load(model_path, map_location=device)
        model.load_state_dict(state_dict)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
    else:
        print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {model_path}")
        return
    
    model.to(device)
    model.eval()
    
    # ë°ì´í„° ì¤€ë¹„
    csv_dir = 'integrations/SignGlove_HW'
    dataset = KSLCsvDataset(csv_dir, window_size=20, stride=10)
    total_size = len(dataset)
    test_size = int(0.2 * total_size)
    test_indices = list(range(total_size - test_size, total_size))
    test_dataset = Subset(dataset, test_indices)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ ìƒ˜í”Œ")
    
    # ONNX ë‚´ë³´ë‚´ê¸°
    output_dir = Path('optimization/compressed_models')
    dummy_input = torch.randn(1, 20, 8)
    onnx_path = output_dir / 'optimized_model.onnx'
    
    print("ğŸ“¦ ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì¤‘...")
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        input_names=['sensor_data'],
        output_names=['class_logits', 'features', 'attention_weights'],
        dynamic_axes={
            'sensor_data': {0: 'batch_size'},
            'class_logits': {0: 'batch_size'},
            'features': {0: 'batch_size'},
            'attention_weights': {0: 'batch_size'}
        }
    )
    
    print(f"âœ… ONNX ëª¨ë¸ ìƒì„±: {onnx_path}")
    
    # ONNX Runtimeìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
    import onnxruntime as ort
    
    print("ğŸ” ONNX Runtime ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    ort_session = ort.InferenceSession(str(onnx_path))
    
    correct = 0
    total = 0
    inference_times = []
    
    for data, targets in test_loader:
        data_np = data.numpy().astype(np.float32)
        
        start_time = time.time()
        ort_inputs = {'sensor_data': data_np}
        ort_outputs = ort_session.run(None, ort_inputs)
        inference_time = (time.time() - start_time) * 1000
        
        # class_logitsë§Œ ì‚¬ìš© (ì²« ë²ˆì§¸ ì¶œë ¥)
        logits = torch.from_numpy(ort_outputs[0])
        _, predicted = torch.max(logits, 1)
        total += targets.size(0)
        correct += (predicted == targets).sum().item()
        inference_times.append(inference_time)
    
    accuracy = 100 * correct / total
    avg_inference_time = np.mean(inference_times)
    fps = 1000 / avg_inference_time if avg_inference_time > 0 else 0
    
    # ëª¨ë¸ í¬ê¸° í™•ì¸
    onnx_size_mb = os.path.getsize(onnx_path) / 1024 / 1024
    
    print(f"\nğŸ“Š ONNX ì„±ëŠ¥ ê²°ê³¼:")
    print(f"  ì •í™•ë„: {accuracy:.2f}%")
    print(f"  ëª¨ë¸ í¬ê¸°: {onnx_size_mb:.2f} MB")
    print(f"  ì¶”ë¡  ì†ë„: {avg_inference_time:.2f} ms")
    print(f"  FPS: {fps:.1f}")
    
    # ê²°ê³¼ ì €ì¥
    onnx_results = {
        'accuracy': accuracy,
        'model_size_mb': onnx_size_mb,
        'inference_time_ms': avg_inference_time,
        'fps': fps
    }
    
    results_path = output_dir / 'onnx_results.json'
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump(onnx_results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ONNX ê²°ê³¼ ì €ì¥: {results_path}")
    
    return onnx_results

if __name__ == "__main__":
    run_onnx_optimization()
