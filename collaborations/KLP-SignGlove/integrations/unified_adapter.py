"""
SignGlove_HW Unified ë°ì´í„°ì…‹ ì–´ëŒ‘í„°
Unified ë°ì´í„°ì…‹ì„ KLP-SignGlove í”„ë¡œì íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import pandas as pd
import numpy as np
import os
import re
from typing import Dict, List, Tuple
import glob

class UnifiedDataAdapter:
    """SignGlove_HW Unified ë°ì´í„°ì…‹ ì–´ëŒ‘í„°"""
    
    def __init__(self):
        self.unified_data_dir = "unified_dataset"
        self.output_dir = "integrations/SignGlove_HW"
        
    def download_unified_dataset(self, max_files_per_class: int = 5):
        """Unified ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
        print("ğŸ“¥ SignGlove_HW Unified ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        
        # GitHub APIë¡œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        import requests
        import json
        
        api_url = "https://api.github.com/repos/KNDG01001/SignGlove_HW/contents/unified"
        response = requests.get(api_url)
        
        if response.status_code != 200:
            print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            return False
            
        files = response.json()
        csv_files = [f for f in files if f['name'].endswith('.csv')]
        
        # í´ë˜ìŠ¤ë³„ë¡œ íŒŒì¼ ê·¸ë£¹í™”
        class_files = {}
        for file_info in csv_files:
            filename = file_info['name']
            # íŒŒì¼ëª…ì—ì„œ í´ë˜ìŠ¤ ì¶”ì¶œ: episode_20250819_152212_ã„±.csv -> ã„±
            match = re.search(r'_([ã„±-ã…ã…-ã…£])\.csv$', filename)
            if match:
                class_name = match.group(1)
                if class_name not in class_files:
                    class_files[class_name] = []
                class_files[class_name].append(file_info)
        
        print(f"ğŸ“Š ë°œê²¬ëœ í´ë˜ìŠ¤: {list(class_files.keys())}")
        
        # ê° í´ë˜ìŠ¤ë³„ë¡œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        downloaded_count = 0
        for class_name, file_list in class_files.items():
            print(f"  ğŸ“ {class_name} í´ë˜ìŠ¤: {len(file_list)}ê°œ íŒŒì¼")
            
            # ê° í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ íŒŒì¼ ìˆ˜ë§Œí¼ ë‹¤ìš´ë¡œë“œ
            for i, file_info in enumerate(file_list[:max_files_per_class]):
                filename = file_info['name']
                download_url = file_info['download_url']
                
                output_path = os.path.join(self.unified_data_dir, filename)
                
                print(f"    ğŸ“¥ ë‹¤ìš´ë¡œë“œ: {filename}")
                response = requests.get(download_url)
                
                if response.status_code == 200:
                    os.makedirs(self.unified_data_dir, exist_ok=True)
                    with open(output_path, 'wb') as f:
                        f.write(response.content)
                    downloaded_count += 1
                else:
                    print(f"    âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {filename}")
        
        print(f"âœ… ì´ {downloaded_count}ê°œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        return True
    
    def convert_unified_to_ksl_format(self, input_file: str, output_file: str) -> pd.DataFrame:
        """Unified í˜•ì‹ì„ KSL í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # Unified ë°ì´í„° ë¡œë“œ
            df = pd.read_csv(input_file)
            print(f"  ğŸ“„ ë¡œë“œ: {os.path.basename(input_file)} ({len(df)}ê°œ ìƒ˜í”Œ)")
            
            # ì»¬ëŸ¼ ë§¤í•‘
            column_mapping = {
                'timestamp_ms': 'timestamp(ms)',
                'pitch': 'pitch(Â°)',
                'roll': 'roll(Â°)', 
                'yaw': 'yaw(Â°)',
                'flex1': 'flex1',
                'flex2': 'flex2',
                'flex3': 'flex3',
                'flex4': 'flex4',
                'flex5': 'flex5'
            }
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ì´ë¦„ ë³€ê²½
            ksl_df = df[list(column_mapping.keys())].copy()
            ksl_df.columns = list(column_mapping.values())
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
            if 'timestamp(ms)' in ksl_df.columns:
                ksl_df['timestamp(ms)'] = ksl_df['timestamp(ms)'].astype(float)
            
            # KSL í˜•ì‹ìœ¼ë¡œ ì €ì¥
            ksl_df.to_csv(output_file, index=False)
            print(f"  âœ… ë³€í™˜ ì™„ë£Œ: {os.path.basename(output_file)}")
            
            return ksl_df
            
        except Exception as e:
            print(f"  âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def process_all_unified_data(self):
        """ëª¨ë“  Unified ë°ì´í„°ë¥¼ KSL í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        print("ğŸ”„ Unified ë°ì´í„°ë¥¼ KSL í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
        
        # Unified ë°ì´í„° íŒŒì¼ë“¤ ì°¾ê¸°
        unified_files = glob.glob(os.path.join(self.unified_data_dir, "*.csv"))
        
        if not unified_files:
            print("âŒ Unified ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        converted_count = 0
        class_stats = {}
        
        for unified_file in unified_files:
            filename = os.path.basename(unified_file)
            
            # íŒŒì¼ëª…ì—ì„œ í´ë˜ìŠ¤ ì¶”ì¶œ
            match = re.search(r'_([ã„±-ã…ã…-ã…£])\.csv$', filename)
            if not match:
                continue
                
            class_name = match.group(1)
            
            # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
            output_filename = f"{class_name}_unified_data_{converted_count:03d}.csv"
            output_path = os.path.join(self.output_dir, output_filename)
            
            # ë³€í™˜ ì‹¤í–‰
            converted_df = self.convert_unified_to_ksl_format(unified_file, output_path)
            
            if not converted_df.empty:
                converted_count += 1
                if class_name not in class_stats:
                    class_stats[class_name] = 0
                class_stats[class_name] += 1
        
        print(f"âœ… ì´ {converted_count}ê°œ íŒŒì¼ ë³€í™˜ ì™„ë£Œ")
        print("ğŸ“Š í´ë˜ìŠ¤ë³„ ë³€í™˜ í†µê³„:")
        for class_name, count in class_stats.items():
            print(f"  {class_name}: {count}ê°œ")
        
        return True
    
    def analyze_unified_data(self):
        """Unified ë°ì´í„° ë¶„ì„"""
        print("ğŸ“Š Unified ë°ì´í„° ë¶„ì„ ì¤‘...")
        
        unified_files = glob.glob(os.path.join(self.unified_data_dir, "*.csv"))
        
        if not unified_files:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        class_data = {}
        
        for file_path in unified_files[:5]:  # ì²˜ìŒ 5ê°œ íŒŒì¼ë§Œ ë¶„ì„
            filename = os.path.basename(file_path)
            match = re.search(r'_([ã„±-ã…ã…-ã…£])\.csv$', filename)
            
            if match:
                class_name = match.group(1)
                
                try:
                    df = pd.read_csv(file_path)
                    
                    if class_name not in class_data:
                        class_data[class_name] = {
                            'samples': [],
                            'columns': list(df.columns)
                        }
                    
                    class_data[class_name]['samples'].append({
                        'file': filename,
                        'rows': len(df),
                        'pitch_range': (df['pitch'].min(), df['pitch'].max()),
                        'roll_range': (df['roll'].min(), df['roll'].max()),
                        'yaw_range': (df['yaw'].min(), df['yaw'].max()),
                        'flex_ranges': [
                            (df['flex1'].min(), df['flex1'].max()),
                            (df['flex2'].min(), df['flex2'].max()),
                            (df['flex3'].min(), df['flex3'].max()),
                            (df['flex4'].min(), df['flex4'].max()),
                            (df['flex5'].min(), df['flex5'].max())
                        ]
                    })
                    
                except Exception as e:
                    print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {filename} - {e}")
        
        # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print("ğŸ“ˆ ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
        for class_name, data in class_data.items():
            print(f"\nğŸ¯ {class_name} í´ë˜ìŠ¤:")
            print(f"  ğŸ“„ ì»¬ëŸ¼: {data['columns']}")
            print(f"  ğŸ“Š ìƒ˜í”Œ ìˆ˜: {len(data['samples'])}")
            
            for sample in data['samples']:
                print(f"    ğŸ“ {sample['file']}: {sample['rows']}í–‰")
                print(f"      ğŸ“ Pitch: {sample['pitch_range'][0]:.2f} ~ {sample['pitch_range'][1]:.2f}")
                print(f"      ğŸ“ Roll: {sample['roll_range'][0]:.2f} ~ {sample['roll_range'][1]:.2f}")
                print(f"      ğŸ“ Yaw: {sample['yaw_range'][0]:.2f} ~ {sample['yaw_range'][1]:.2f}")
                print(f"      ğŸ”§ Flex: {[f'{r[0]:.0f}~{r[1]:.0f}' for r in sample['flex_ranges']]}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    adapter = UnifiedDataAdapter()
    
    # 1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    if not adapter.download_unified_dataset(max_files_per_class=3):
        print("âŒ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return
    
    # 2. ë°ì´í„° ë¶„ì„
    adapter.analyze_unified_data()
    
    # 3. KSL í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    if adapter.process_all_unified_data():
        print("ğŸ‰ Unified ë°ì´í„° í†µí•© ì™„ë£Œ!")
    else:
        print("âŒ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()

