#!/usr/bin/env python3
"""
Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨ V2
ìƒˆë¡œìš´ Episode ì „ìš© ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
"""

import sys
import os
import time
import json
import glob
import numpy as np
from pathlib import Path
import pandas as pd
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from inference.episode_inference import (
    EpisodeInferencePipeline, 
    EpisodeSensorReading, 
    create_episode_inference_pipeline
)

class EpisodeRealtimeDemoV2:
    """Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨ V2"""
    
    def __init__(self):
        self.pipeline = None
        self.results_log = []
        
    def setup_episode_pipeline(self):
        """Episode ë°ì´í„°ìš© ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        print("ğŸš€ Episode ë°ì´í„° ê¸°ë°˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ V2 ì´ˆê¸°í™”")
        print("=" * 70)
        
        # ê· í˜•ì¡íŒ Episode ëª¨ë¸ ì‚¬ìš© (99.92% ì •í™•ë„)
        config = {
            'window_size': 20
        }
        self.pipeline = create_episode_inference_pipeline(
            model_path="best_balanced_episode_model.pth",
            config=config
        )
            
        print("âœ… Episode ì¶”ë¡  íŒŒì´í”„ë¼ì¸ V2 ì´ˆê¸°í™” ì™„ë£Œ")
            
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        stats = self.pipeline.get_performance_stats()
        print(f"ğŸ“Š ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ:")
        print(f"  - ìœˆë„ìš° í¬ê¸°: {stats['window_size']}")
        print(f"  - ë²„í¼ í¬ê¸°: {stats['buffer_size']}")
        print(f"  - ì¥ì¹˜: {stats['device']}")
        
    def load_episode_sensor_data(self) -> List[Dict]:
        """Episode ì„¼ì„œ ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“ Episode ì„¼ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        sensor_data = []
        # Episode CSV íŒŒì¼ë“¤ ì°¾ê¸°
        data_sources = glob.glob(os.path.join("integrations/SignGlove_HW/github_unified_data", "**/episode_*.csv"), recursive=True)
        
        print(f"ğŸ“ ë°œê²¬ëœ Episode íŒŒì¼: {len(data_sources)}ê°œ")
        
        # ë‹¤ì–‘í•œ í´ë˜ìŠ¤ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ê° í´ë˜ìŠ¤ë³„ë¡œ íŒŒì¼ ì„ íƒ
        class_files = {}
        for data_file in data_sources:
            filename = os.path.basename(data_file)
            
            # ë¼ë²¨ ì¶”ì¶œ
            ground_truth = None
            for class_name in ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…', 'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£']:
                if f'_{class_name}_' in filename:
                    ground_truth = class_name
                    break
            
            if ground_truth and ground_truth not in class_files:
                class_files[ground_truth] = data_file
        
        # ê° í´ë˜ìŠ¤ë³„ë¡œ íŒŒì¼ ì²˜ë¦¬
        for class_name, data_file in class_files.items():
            if os.path.exists(data_file):
                try:
                    df = pd.read_csv(data_file)
                    print(f"  ğŸ“„ ë¡œë“œ: {os.path.basename(data_file)} ({len(df)}ê°œ ìƒ˜í”Œ)")
                    
                    # ì´ë¯¸ ì¶”ì¶œëœ ë¼ë²¨ ì‚¬ìš©
                    ground_truth = class_name
                    filename = os.path.basename(data_file)
                    print(f"  âœ… ë¼ë²¨: {ground_truth}")
                    
                    # ë°ì´í„° ë³€í™˜ (Episode í˜•íƒœ)
                    class_samples = 0
                    for idx, row in df.iterrows():
                        try:
                            # Episode ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜
                            available_cols = df.columns.tolist()
                            
                            # Flex ì„¼ì„œ ì»¬ëŸ¼ ì°¾ê¸°
                            flex_cols = []
                            for i in range(1, 6):
                                flex_patterns = [f'flex{i}', f'Flex{i}', f'FLEX{i}']
                                for pattern in flex_patterns:
                                    if pattern in available_cols:
                                        flex_cols.append(pattern)
                                        break
                            
                            # Orientation ì»¬ëŸ¼ ì°¾ê¸°
                            pitch_col = None
                            roll_col = None
                            yaw_col = None
                            
                            for col in available_cols:
                                if 'pitch' in col.lower():
                                    pitch_col = col
                                elif 'roll' in col.lower():
                                    roll_col = col
                                elif 'yaw' in col.lower():
                                    yaw_col = col
                            
                            if not flex_cols or not all([pitch_col, roll_col, yaw_col]):
                                continue
                            
                            # ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ
                            flex_data = [float(row[col]) for col in flex_cols]
                            orientation_data = [float(row[pitch_col]), float(row[roll_col]), float(row[yaw_col])]
                            
                            sensor_data.append({
                                'flex_data': flex_data,
                                'orientation_data': orientation_data,
                                'ground_truth': ground_truth,
                                'file': filename,
                                'row': idx
                            })
                            
                            class_samples += 1
                            
                            # í´ë˜ìŠ¤ë‹¹ ìµœëŒ€ 50ê°œ ìƒ˜í”Œë¡œ ì œí•œ
                            if class_samples >= 50:
                                break
                                
                        except Exception as e:
                            print(f"  âš ï¸ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
                            continue
                    
                    print(f"  ğŸ“Š ë³€í™˜ëœ ìƒ˜í”Œ: {class_samples}ê°œ")
                    
                except Exception as e:
                    print(f"  âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {data_file} - {e}")
                    continue
        
        print(f"âœ… ì´ {len(sensor_data)}ê°œ ì„¼ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return sensor_data
    
    def run_comprehensive_test(self, sensor_data: List[Dict]):
        """í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\nğŸ¯ í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        total_tests = len(sensor_data)
        correct_predictions = 0
        class_performance = {}
        confidence_scores = []
        
        print(f"ğŸ“Š ì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        for i, data_item in enumerate(sensor_data):
            if i % 100 == 0:
                progress = (i / total_tests) * 100
                print(f"  ì§„í–‰ë¥ : {i}/{total_tests} ({progress:.1f}%)")
            
            try:
                # íŒŒì´í”„ë¼ì¸ì— ë°ì´í„° ì¶”ê°€
                success = self.pipeline.add_sensor_data(
                    data_item['flex_data'],
                    data_item['orientation_data']
                )
                
                if not success:
                    continue
                
                # ì¶”ë¡  ì‹¤í–‰
                result = self.pipeline.predict_single(
                    expected_class=data_item['ground_truth']
                )
                
                if result is None:
                    continue
                
                # ê²°ê³¼ ë¶„ì„
                if result.correct:
                    correct_predictions += 1
                
                # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì¶”ì 
                class_name = data_item['ground_truth']
                if class_name not in class_performance:
                    class_performance[class_name] = {'total': 0, 'correct': 0}
                
                class_performance[class_name]['total'] += 1
                if result.correct:
                    class_performance[class_name]['correct'] += 1
                
                # ì‹ ë¢°ë„ ê¸°ë¡
                confidence_scores.append(result.confidence)
                
                # ê²°ê³¼ ë¡œê·¸
                self.results_log.append({
                    'file': data_item['file'],
                    'row': data_item['row'],
                    'ground_truth': data_item['ground_truth'],
                    'predicted': result.predicted_class,
                    'confidence': result.confidence,
                    'correct': result.correct,
                    'processing_time': result.processing_time
                })
                
            except Exception as e:
                print(f"  âš ï¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
                continue
        
        # ê²°ê³¼ ë¶„ì„
        overall_accuracy = (correct_predictions / total_tests) * 100 if total_tests > 0 else 0
        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0
        min_confidence = np.min(confidence_scores) if confidence_scores else 0
        max_confidence = np.max(confidence_scores) if confidence_scores else 0
        
        print(f"âœ… í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {correct_predictions}ê°œ ì˜ˆì¸¡")
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Episode ë°ì´í„° ì¶”ë¡  ê²°ê³¼ ë¶„ì„ V2")
        print("=" * 60)
        print(f"ğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"  ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions}ê°œ")
        print(f"  ì „ì²´ ì •í™•ë„: {overall_accuracy:.2f}%")
        
        print(f"\nğŸ“‹ í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥:")
        print("-" * 60)
        print("í´ë˜ìŠ¤  ì´ìˆ˜     ì •í™•     ì •í™•ë„")
        print("-" * 60)
        
        for class_name in sorted(class_performance.keys()):
            stats = class_performance[class_name]
            accuracy = (stats['correct'] / stats['total']) * 100 if stats['total'] > 0 else 0
            print(f"{class_name:<4} {stats['total']:>6} {stats['correct']:>6} {accuracy:>8.1f} %")
        
        print(f"\nğŸ¯ ì‹ ë¢°ë„ ë¶„ì„:")
        print(f"  ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"  ì‹ ë¢°ë„ ë²”ìœ„: {min_confidence:.3f} ~ {max_confidence:.3f}")
        
        return overall_accuracy, class_performance
    
    def run_realtime_simulation(self, sensor_data: List[Dict]):
        """ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ - ì—°ì† ë°ì´í„° ì‚¬ìš©"""
        print(f"\nğŸ® ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ (ì—°ì† Episode ë°ì´í„°)")
        print("=" * 60)
        
        # í´ë˜ìŠ¤ë³„ë¡œ ì—°ì† ë°ì´í„° ê·¸ë£¹í™”
        class_sequences = {}
        for data_item in sensor_data:
            class_name = data_item['ground_truth']
            if class_name not in class_sequences:
                class_sequences[class_name] = []
            class_sequences[class_name].append(data_item)
        
        total_tests = 0
        correct_tests = 0
        
        for class_name in sorted(class_sequences.keys()):
            sequence = class_sequences[class_name]
            if len(sequence) < 20:  # ìµœì†Œ ìœˆë„ìš° í¬ê¸°
                continue
                
            print(f"\nğŸ” {class_name} ì—°ì† í…ŒìŠ¤íŠ¸ (ì´ {len(sequence)}ê°œ ìƒ˜í”Œ):")
            class_correct = 0
            
            # ë²„í¼ ì´ˆê¸°í™”
            self.pipeline.data_buffer.clear()
            
            # ì—°ì†ì ìœ¼ë¡œ ë°ì´í„° ì¶”ê°€í•˜ë©´ì„œ ì¶”ë¡ 
            for i, sample in enumerate(sequence):
                try:
                    # íŒŒì´í”„ë¼ì¸ì— ë°ì´í„° ì¶”ê°€
                    success = self.pipeline.add_sensor_data(
                        sample['flex_data'],
                        sample['orientation_data']
                    )
                    
                    if not success:
                        continue
                    
                    # ìœˆë„ìš°ê°€ ì¶©ë¶„íˆ ìŒ“ì¸ í›„ë¶€í„° ì¶”ë¡  ì‹œì‘
                    if len(self.pipeline.data_buffer) >= self.pipeline.window_size:
                        # ì¶”ë¡  ì‹¤í–‰
                        result = self.pipeline.predict_single(
                            expected_class=sample['ground_truth']
                        )
                        
                        if result is None:
                            continue
                        
                        status = "âœ…" if result.correct else "âŒ"
                        print(f"  {status} ìƒ˜í”Œ {i+1}: {sample['ground_truth']} â†’ {result.predicted_class} (ì‹ ë¢°ë„: {result.confidence:.3f})")
                        
                        if result.correct:
                            class_correct += 1
                            correct_tests += 1
                        
                        total_tests += 1
                        
                        # 10ê°œ ìƒ˜í”Œë§ˆë‹¤ ê²°ê³¼ ì¶œë ¥ (ë„ˆë¬´ ë§ì€ ì¶œë ¥ ë°©ì§€)
                        if total_tests % 10 == 0:
                            print(f"    ... ì§„í–‰ë¥ : {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"  âš ï¸ ìƒ˜í”Œ {i+1}: ì¶”ë¡  ì‹¤íŒ¨ - {e}")
                    continue
            
            class_accuracy = (class_correct / max(1, total_tests - (total_tests - class_correct))) * 100
            print(f"  ğŸ“Š {class_name} ì •í™•ë„: {class_accuracy:.1f}% ({class_correct}/{max(1, total_tests - (total_tests - class_correct))})")
        
        overall_accuracy = (correct_tests / total_tests) * 100 if total_tests > 0 else 0
        print(f"\nğŸ¯ ì „ì²´ ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"  ì •í™•í•œ ì˜ˆì¸¡: {correct_tests}ê°œ")
        print(f"  ì „ì²´ ì •í™•ë„: {overall_accuracy:.2f}%")
        
        return overall_accuracy
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        results = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'model': 'best_balanced_episode_model.pth',
            'pipeline': 'EpisodeInferencePipeline V2',
            'results': self.results_log
        }
        
        with open('episode_inference_demo_v2_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print("âœ… ê²°ê³¼ ì €ì¥: episode_inference_demo_v2_results.json")
    
    def run_demo(self):
        """ì „ì²´ ë°ëª¨ ì‹¤í–‰"""
        print("ğŸš€ Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨ V2 ì‹œì‘")
        print("=" * 70)
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.setup_episode_pipeline()
        
        # ë°ì´í„° ë¡œë“œ
        sensor_data = self.load_episode_sensor_data()
        
        if not sensor_data:
            print("âŒ ë¡œë“œëœ ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í¬ê´„ì  í…ŒìŠ¤íŠ¸
        overall_accuracy, class_performance = self.run_comprehensive_test(sensor_data)
        
        # ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        realtime_accuracy = self.run_realtime_simulation(sensor_data)
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
        
        print(f"\nğŸ‰ Episode ë°ì´í„° ì¶”ë¡  ë°ëª¨ V2 ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥:")
        print(f"  - í¬ê´„ì  í…ŒìŠ¤íŠ¸: {overall_accuracy:.2f}%")
        print(f"  - ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜: {realtime_accuracy:.2f}%")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    demo = EpisodeRealtimeDemoV2()
    demo.run_demo()

if __name__ == "__main__":
    main()
