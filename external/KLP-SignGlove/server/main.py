"""
SignGlove ì¶”ë¡  API ì„œë²„
FastAPIë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹ API
"""

import os
import sys
import time
import json
import asyncio
from typing import Dict, List, Optional, Any
from pathlib import Path

# FastAPI ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from inference.unified_inference import (
    UnifiedInferencePipeline, 
    SensorReading, 
    InferenceMode,
    create_unified_inference_pipeline
)
from training.label_mapping import KSLLabelMapper
from word_recognition import WordRecognitionSystem

# Pydantic ëª¨ë¸ ì •ì˜
class SensorDataRequest(BaseModel):
    """ì„¼ì„œ ë°ì´í„° ìš”ì²­ ëª¨ë¸"""
    timestamp: float = Field(..., description="íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ)")
    pitch: float = Field(..., description="í”¼ì¹˜ ê°ë„ (ë„)")
    roll: float = Field(..., description="ë¡¤ ê°ë„ (ë„)")
    yaw: float = Field(..., description="ìš” ê°ë„ (ë„)")
    flex1: int = Field(..., description="í”Œë ‰ìŠ¤ ì„¼ì„œ 1 ê°’")
    flex2: int = Field(..., description="í”Œë ‰ìŠ¤ ì„¼ì„œ 2 ê°’")
    flex3: int = Field(..., description="í”Œë ‰ìŠ¤ ì„¼ì„œ 3 ê°’")
    flex4: int = Field(..., description="í”Œë ‰ìŠ¤ ì„¼ì„œ 4 ê°’")
    flex5: int = Field(..., description="í”Œë ‰ìŠ¤ ì„¼ì„œ 5 ê°’")
    source: str = Field(default="api", description="ë°ì´í„° ì†ŒìŠ¤")

class BatchSensorDataRequest(BaseModel):
    """ë°°ì¹˜ ì„¼ì„œ ë°ì´í„° ìš”ì²­ ëª¨ë¸"""
    sensor_data: List[SensorDataRequest] = Field(..., description="ì„¼ì„œ ë°ì´í„° ë°°ì—´")
    window_size: int = Field(default=20, description="ìœˆë„ìš° í¬ê¸°")
    stride: int = Field(default=10, description="ìŠ¤íŠ¸ë¼ì´ë“œ")

class PredictionResponse(BaseModel):
    """ì˜ˆì¸¡ ì‘ë‹µ ëª¨ë¸"""
    predicted_class: str = Field(..., description="ì˜ˆì¸¡ëœ í´ë˜ìŠ¤")
    confidence: float = Field(..., description="ì˜ˆì¸¡ ì‹ ë¢°ë„ (0.0-1.0)")
    stability_score: float = Field(..., description="ì•ˆì •ì„± ì ìˆ˜")
    processing_time_ms: float = Field(..., description="ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)")
    timestamp: float = Field(..., description="ì‘ë‹µ íƒ€ì„ìŠ¤íƒ¬í”„")

class ModelInfoResponse(BaseModel):
    """ëª¨ë¸ ì •ë³´ ì‘ë‹µ ëª¨ë¸"""
    model_name: str = Field(..., description="ëª¨ë¸ ì´ë¦„")
    model_version: str = Field(..., description="ëª¨ë¸ ë²„ì „")
    accuracy: float = Field(..., description="í…ŒìŠ¤íŠ¸ ì •í™•ë„")
    num_classes: int = Field(..., description="ì§€ì› í´ë˜ìŠ¤ ìˆ˜")
    supported_classes: List[str] = Field(..., description="ì§€ì› í´ë˜ìŠ¤ ëª©ë¡")
    input_features: int = Field(..., description="ì…ë ¥ íŠ¹ì„± ìˆ˜")
    window_size: int = Field(..., description="ìœˆë„ìš° í¬ê¸°")

class PerformanceStatsResponse(BaseModel):
    """ì„±ëŠ¥ í†µê³„ ì‘ë‹µ ëª¨ë¸"""
    fps: float = Field(..., description="ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜")
    avg_latency_ms: float = Field(..., description="í‰ê·  ì§€ì—°ì‹œê°„ (ë°€ë¦¬ì´ˆ)")
    total_predictions: int = Field(..., description="ì´ ì˜ˆì¸¡ ìˆ˜")
    buffer_utilization: float = Field(..., description="ë²„í¼ ì‚¬ìš©ë¥ ")
    confidence_threshold: float = Field(..., description="ì‹ ë¢°ë„ ì„ê³„ê°’")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="SignGlove ì¶”ë¡  API",
    description="ì‹¤ì‹œê°„ í•œêµ­ìˆ˜ì–´ ì¸ì‹ì„ ìœ„í•œ ì¶”ë¡  API ì„œë²„",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
inference_pipeline: Optional[UnifiedInferencePipeline] = None
label_mapper: Optional[KSLLabelMapper] = None
model_info: Dict[str, Any] = {}
word_recognition_system: Optional[WordRecognitionSystem] = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global inference_pipeline, label_mapper, model_info, word_recognition_system
    
    print("ğŸš€ SignGlove ì¶”ë¡  API ì„œë²„ ì‹œì‘ ì¤‘...")
    
    try:
        # ë¼ë²¨ ë§¤í¼ ì´ˆê¸°í™”
        label_mapper = KSLLabelMapper()
        
        # ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ìƒˆë¡œìš´ Episode ëª¨ë¸ ì‚¬ìš©)
        model_path = "best_balanced_episode_model.pth"
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        inference_pipeline = create_unified_inference_pipeline(
            model_path=model_path,
            config_path=None
        )
        
        # ëª¨ë¸ ì •ë³´ ì„¤ì • (ìƒˆë¡œìš´ Episode ëª¨ë¸ ì •ë³´)
        model_info = {
            "model_name": "SignGlove Balanced Episode Model",
            "model_version": "2.0.0",
            "accuracy": 0.9989,  # ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ì •í™•ë„
            "num_classes": 24,
            "supported_classes": list(label_mapper.class_to_id.keys()),
            "input_features": 8,
            "window_size": 20
        }
        
        # ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        word_recognition_system = WordRecognitionSystem()
        
        print("âœ… API ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´: {model_info['model_name']} v{model_info['model_version']}")
        print(f"ğŸ¯ ì •í™•ë„: {model_info['accuracy']:.2%}")
        print(f"ğŸ“ˆ ì§€ì› í´ë˜ìŠ¤: {model_info['num_classes']}ê°œ")
        print(f"ğŸ“ ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œ: í™œì„±í™”")
        
    except Exception as e:
        print(f"âŒ ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    global inference_pipeline
    
    if inference_pipeline:
        inference_pipeline.stop_realtime_inference()
        print("ğŸ›‘ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ")

@app.get("/", response_model=Dict[str, str])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "SignGlove ì¶”ë¡  API ì„œë²„",
        "version": "1.0.0",
        "status": "running",
        "docs": "/docs"
    }

@app.get("/health", response_model=Dict[str, Any])
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì„±ëŠ¥ í†µê³„ ê°€ì ¸ì˜¤ê¸°
    stats = inference_pipeline.get_performance_stats()
    
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "model_loaded": True,
        "performance_stats": stats
    }

@app.get("/model/info", response_model=ModelInfoResponse)
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    global model_info
    
    if not model_info:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return ModelInfoResponse(**model_info)

@app.get("/model/performance", response_model=PerformanceStatsResponse)
async def get_performance_stats():
    """ì„±ëŠ¥ í†µê³„ ì¡°íšŒ"""
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    stats = inference_pipeline.get_performance_stats()
    return PerformanceStatsResponse(**stats)

@app.post("/predict", response_model=PredictionResponse)
async def predict_gesture(request: SensorDataRequest):
    """
    ë‹¨ì¼ ì„¼ì„œ ë°ì´í„°ë¡œ ì œìŠ¤ì²˜ ì˜ˆì¸¡
    
    Args:
        request: ì„¼ì„œ ë°ì´í„° ìš”ì²­
        
    Returns:
        PredictionResponse: ì˜ˆì¸¡ ê²°ê³¼
    """
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    start_time = time.time()
    
    try:
        # ì„¼ì„œ ë°ì´í„°ë¥¼ SensorReadingìœ¼ë¡œ ë³€í™˜
        sensor_reading = SensorReading(
            timestamp=request.timestamp,
            flex_data=[request.flex1, request.flex2, request.flex3, request.flex4, request.flex5],
            orientation_data=[request.pitch, request.roll, request.yaw],
            source=request.source
        )
        
        # ì„¼ì„œ ë°ì´í„° ì¶”ê°€
        success = inference_pipeline.add_sensor_data(sensor_reading)
        
        if not success:
            raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        result = inference_pipeline.predict_single()
        
        if result is None:
            raise HTTPException(status_code=400, detail="ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¶©ë¶„í•œ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        processing_time = (time.time() - start_time) * 1000  # ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
        
        return PredictionResponse(
            predicted_class=result.predicted_class,
            confidence=result.confidence,
            stability_score=result.stability_score,
            processing_time_ms=processing_time,
            timestamp=time.time()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/predict/batch", response_model=List[PredictionResponse])
async def predict_gesture_batch(request: BatchSensorDataRequest):
    """
    ë°°ì¹˜ ì„¼ì„œ ë°ì´í„°ë¡œ ì œìŠ¤ì²˜ ì˜ˆì¸¡
    
    Args:
        request: ë°°ì¹˜ ì„¼ì„œ ë°ì´í„° ìš”ì²­
        
    Returns:
        List[PredictionResponse]: ì˜ˆì¸¡ ê²°ê³¼ ë°°ì—´
    """
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    if len(request.sensor_data) == 0:
        raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    results = []
    
    try:
        for sensor_request in request.sensor_data:
            start_time = time.time()
            
            # ì„¼ì„œ ë°ì´í„°ë¥¼ SensorReadingìœ¼ë¡œ ë³€í™˜
            sensor_reading = SensorReading(
                timestamp=sensor_request.timestamp,
                flex_data=[sensor_request.flex1, sensor_request.flex2, sensor_request.flex3, sensor_request.flex4, sensor_request.flex5],
                orientation_data=[sensor_request.pitch, sensor_request.roll, sensor_request.yaw],
                source=sensor_request.source
            )
            
            # ì„¼ì„œ ë°ì´í„° ì¶”ê°€
            success = inference_pipeline.add_sensor_data(sensor_reading)
            
            if not success:
                continue
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            result = inference_pipeline.predict_single()
            
            if result is not None:
                processing_time = (time.time() - start_time) * 1000
                
                results.append(PredictionResponse(
                    predicted_class=result.predicted_class,
                    confidence=result.confidence,
                    stability_score=result.stability_score,
                    processing_time_ms=processing_time,
                    timestamp=time.time()
                ))
        
        return results
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/predict/stable", response_model=PredictionResponse)
async def predict_stable_gesture(request: SensorDataRequest):
    """
    ì•ˆì •ì ì¸ ì œìŠ¤ì²˜ ì˜ˆì¸¡ (ì•ˆì •ì„± ì²´í¬ í¬í•¨)
    
    Args:
        request: ì„¼ì„œ ë°ì´í„° ìš”ì²­
        
    Returns:
        PredictionResponse: ì•ˆì •ì ì¸ ì˜ˆì¸¡ ê²°ê³¼
    """
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    start_time = time.time()
    
    try:
        # ì„¼ì„œ ë°ì´í„°ë¥¼ SensorReadingìœ¼ë¡œ ë³€í™˜
        sensor_reading = SensorReading(
            timestamp=request.timestamp,
            flex_data=[request.flex1, request.flex2, request.flex3, request.flex4, request.flex5],
            orientation_data=[request.pitch, request.roll, request.yaw],
            source=request.source
        )
        
        # ì„¼ì„œ ë°ì´í„° ì¶”ê°€
        success = inference_pipeline.add_sensor_data(sensor_reading)
        
        if not success:
            raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨")
        
        # ì•ˆì •ì ì¸ ì˜ˆì¸¡ ìˆ˜í–‰
        result = inference_pipeline.get_stable_prediction()
        
        if result is None:
            raise HTTPException(status_code=400, detail="ì•ˆì •ì ì¸ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        processing_time = (time.time() - start_time) * 1000
        
        return PredictionResponse(
            predicted_class=result.predicted_class,
            confidence=result.confidence,
            stability_score=result.stability_score,
            processing_time_ms=processing_time,
            timestamp=time.time()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì•ˆì •ì  ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/config/confidence")
async def set_confidence_threshold(request: Dict[str, float]):
    threshold = request.get("threshold", 0.7)
    if not (0.0 <= threshold <= 1.0):
        raise HTTPException(status_code=400, detail="ì„ê³„ê°’ì€ 0.0ê³¼ 1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤")
    """
    ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
    
    Args:
        threshold: ì‹ ë¢°ë„ ì„ê³„ê°’ (0.0-1.0)
    """
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        inference_pipeline.set_confidence_threshold(threshold)
        return {"message": f"ì‹ ë¢°ë„ ì„ê³„ê°’ì´ {threshold}ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„ê³„ê°’ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/buffer/clear")
async def clear_buffers():
    """ë²„í¼ ì´ˆê¸°í™”"""
    global inference_pipeline
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        inference_pipeline.clear_buffers()
        return {"message": "ë²„í¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²„í¼ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/classes", response_model=Dict[str, List[str]])
async def get_supported_classes():
    """ì§€ì› í´ë˜ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
    global label_mapper
    
    if label_mapper is None:
        raise HTTPException(status_code=503, detail="ë¼ë²¨ ë§¤í¼ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    return {
        "consonants": label_mapper.get_consonants(),
        "vowels": label_mapper.get_vowels(),
        "all_classes": list(label_mapper.class_to_id.keys())
    }

@app.post("/word/recognize")
async def recognize_word(request: SensorDataRequest):
    """ë‹¨ì–´ ì¸ì‹"""
    global word_recognition_system, inference_pipeline
    
    if word_recognition_system is None:
        raise HTTPException(status_code=503, detail="ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    if inference_pipeline is None:
        raise HTTPException(status_code=503, detail="ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    try:
        start_time = time.time()
        
        # ì„¼ì„œ ë°ì´í„°ë¥¼ SensorReadingìœ¼ë¡œ ë³€í™˜
        sensor_reading = SensorReading(
            timestamp=request.timestamp,
            flex_data=[request.flex1, request.flex2, request.flex3, request.flex4, request.flex5],
            orientation_data=[request.pitch, request.roll, request.yaw],
            source=request.source
        )
        
        # ì„¼ì„œ ë°ì´í„° ì¶”ê°€
        success = inference_pipeline.add_sensor_data(sensor_reading)
        
        if not success:
            raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        result = inference_pipeline.predict_single()
        
        if result is None:
            # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ìƒíƒœë§Œ ë°˜í™˜
            status = word_recognition_system.get_current_status()
            return {
                "success": True,
                "letter_result": None,
                "word_result": None,
                "current_status": status,
                "timestamp": time.time()
            }
        
        # ê¸€ì ì¸ì‹ ê²°ê³¼
        letter = result.predicted_class
        confidence = result.confidence
        
        # ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œì— ê¸€ì ì¶”ê°€
        word_result = word_recognition_system.add_letter(letter, confidence, time.time())
        
        # í˜„ì¬ ìƒíƒœ
        status = word_recognition_system.get_current_status()
        
        processing_time = (time.time() - start_time) * 1000
        
        return {
            "success": True,
            "letter_result": {
                "letter": letter,
                "confidence": confidence,
                "timestamp": time.time()
            },
            "word_result": {
                "word": word_result.word if word_result else None,
                "confidence": word_result.confidence if word_result else None,
                "timestamp": word_result.timestamp if word_result else None
            },
            "current_status": status,
            "processing_time_ms": processing_time,
            "timestamp": time.time()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë‹¨ì–´ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/word/status")
async def get_word_status():
    """ë‹¨ì–´ ì¸ì‹ ìƒíƒœ ì¡°íšŒ"""
    global word_recognition_system
    
    if word_recognition_system is None:
        raise HTTPException(status_code=503, detail="ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    status = word_recognition_system.get_current_status()
    
    return {
        "status": status,
        "timestamp": time.time()
    }

@app.post("/word/clear")
async def clear_current_word():
    """í˜„ì¬ ë‹¨ì–´ ì´ˆê¸°í™”"""
    global word_recognition_system
    
    if word_recognition_system is None:
        raise HTTPException(status_code=503, detail="ë‹¨ì–´ ì¸ì‹ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    word_recognition_system.clear_current_word()
    
    return {
        "message": "í˜„ì¬ ë‹¨ì–´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤",
        "timestamp": time.time()
    }

if __name__ == "__main__":
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "server.main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )
