# KSL-SignGlove 프로젝트 전체 작업 요약

## 📊 프로젝트 개요
- **목표**: 한국 수어 인식을 위한 SignGlove 센서 데이터 기반 딥러닝 모델 개발
- **데이터**: 24개 한국어 자음/모음 클래스, 각 클래스당 25개 파일
- **센서**: IMU (pitch, roll, yaw) + Flex 센서 (flex1-5)
- **최종 목표**: 실시간 한국 수어 인식 시스템 구축

## 🚀 전체 개발 여정

### Phase 1: 초기 분석 및 문제 발견
#### 1.1 과적합 클래스 분석
- **발견**: 일부 클래스에서 F1-score 1.000 (완벽한 과적합)
- **문제 클래스**: `ㅊ`, `ㅕ` 등에서 심각한 성능 저하
- **해결책**: 시나리오 기반 데이터 분할 도입

#### 1.2 데이터 품질 문제 분석
- **Yaw 드리프트**: 지자기 센서 부재로 인한 적분 누적 오차
- **센서 노이즈**: IMU 및 Flex 센서의 노이즈 문제
- **클래스 불균형**: 데이터 분할 시 발생하는 클래스별 샘플 불균형

### Phase 2: 전처리 파이프라인 개발

#### 2.1 기본 전처리
```python
# 초기 전처리
- 데이터 정규화
- 노이즈 제거
- 이상치 제거
- 데이터 길이 표준화 (패딩/트렁케이션)
```

#### 2.2 보완 필터 (Complementary Filter) 도입
- **목적**: Yaw 드리프트 문제 해결
- **효과**: 클래스 분리도 향상, 노이즈 증가
- **결과**: 특정 클래스 성능 향상, 전체 성능 하락 (86.2% → 48.8%)

#### 2.3 향상된 전처리 파이프라인
```python
# 최종 전처리 구성
- 보완 필터 적용
- 노이즈 제거 및 이상치 제거
- Flex 센서 정규화
- 클래스별 가중치 적용
- 데이터 길이 정규화
- 데이터 증강
```

### Phase 3: 모델 아키텍처 개발

#### 3.1 기본 모델 (DeepLearningPipeline)
```python
# 구조
- CNN + LSTM 조합
- 입력: 8개 특성 (pitch, roll, yaw, flex1-5)
- 출력: 24개 클래스
- 파라미터: 약 50,000개
```

#### 3.2 특화 모델 (SpecializedModel)
```python
# 구조
- Conv1D + BatchNorm + Dropout
- Bidirectional LSTM (2 레이어)
- Multi-head Attention
- 복잡한 분류기
- 파라미터: 약 100,000개
```

#### 3.3 최적화 모델 (OptimizedModel)
```python
# 구조
- Conv1D (5, 3, 3 커널)
- BatchNorm1d + Dropout
- Bidirectional LSTM + Attention
- Residual 연결 분류기
- 파라미터: 122,312개
```

### Phase 4: 데이터 분할 전략 개발

#### 4.1 시나리오 기반 분할
- **문제**: 데이터 누수로 인한 과적합
- **해결**: 수집 시나리오별 분할

#### 4.2 파일 기반 분할
- **개선**: 개별 파일 단위 분할
- **효과**: 모든 클래스가 모든 세트에 포함
- **결과**: 테스트 정확도 91.11% 달성

#### 4.3 계층적 샘플링 (Stratified Sampling)
- **목적**: 클래스별 균등한 샘플링
- **효과**: 테스트 정확도 97.78% 달성
- **문제**: 과적합 위험 (Train-Val Gap 0.1881)

#### 4.4 K-Fold 교차 검증
- **목적**: 과적합 방지 및 안정적 평가
- **구성**: 5-Fold, 강화된 정규화
- **결과**: 평균 검증 정확도 89.67% ± 1.35%

### Phase 5: 성능 분석 및 최적화

#### 5.1 최종 모델 성능 분석
- **전체 정확도**: 77.33%
- **클래스별 성능**:
  - 우수 클래스 (≥95%): 14개
  - 양호 클래스 (80-95%): 2개
  - 저성능 클래스 (<80%): 8개
- **문제 클래스**: `ㅊ` (0% 정확도)

#### 5.2 특화 모델 분석
- **문제 클래스 식별**: `ㅊ`, `ㅌ`, `ㅅ`, `ㅈ`, `ㅋ`, `ㅕ`, `ㅡ`, `ㅣ`
- **공통 문제**: 높은 Yaw 분산
- **해결책**: 클래스별 특화 전처리 및 증강

#### 5.3 앙상블 모델 개발
- **구성**: 교차 검증 모델 + 특화 모델
- **결과**: 76.50% (교차 검증 모델보다 낮음)
- **문제**: 특화 모델의 낮은 성능 (9.50%)

### Phase 6: 최적화 시도

#### 6.1 교차 검증 모델 최적화
- **목표**: 77.33% → 80% 이상
- **접근법**: 분석 기반 최적화된 전처리
- **특징**:
  - 클래스별 특화 강화
  - 향상된 센서 신호 처리
  - 고급 정규화 기법

## 📈 성능 진화 과정

### 모델별 성능 비교
```
1. 기본 모델: ~60% (과적합 문제)
2. 시나리오 분할: ~70% (과적합 해결)
3. 파일 기반 분할: 91.11% (균형 개선)
4. 계층적 샘플링: 97.78% (최고 성능, 과적합 위험)
5. 교차 검증: 89.67% ± 1.35% (안정적)
6. 최종 테스트: 77.33% (실제 성능)
7. 앙상블: 76.50% (성능 하락)
8. 최적화 시도: 진행 중 (목표 >80%)
```

### 클래스별 성능 분석
#### 우수 클래스 (≥95%)
- `ㄱ`, `ㄴ`, `ㄷ`, `ㄹ`, `ㅁ`, `ㅂ`, `ㅇ`, `ㅎ`, `ㅏ`, `ㅑ`, `ㅓ`, `ㅗ`, `ㅛ`, `ㅜ`

#### 양호 클래스 (80-95%)
- `ㅠ`, `ㅍ`

#### 저성능 클래스 (<80%)
- `ㅅ`, `ㅈ`, `ㅊ`, `ㅋ`, `ㅌ`, `ㅕ`, `ㅡ`, `ㅣ`

## 🔧 핵심 기술적 성과

### 1. 전처리 기술
- **보완 필터**: Yaw 드리프트 문제 해결
- **클래스별 특화 처리**: 문제 클래스별 맞춤 전처리
- **다단계 필터링**: 노이즈 제거 및 신호 강화

### 2. 모델 아키텍처
- **CNN+LSTM**: 기본 구조
- **Attention 메커니즘**: 시퀀스 중요도 학습
- **Bidirectional LSTM**: 양방향 정보 활용

### 3. 정규화 기법
- **Dropout**: 과적합 방지
- **BatchNorm**: 훈련 안정화
- **L2 정규화**: 가중치 제한
- **Gradient Clipping**: 그래디언트 폭발 방지

### 4. 데이터 분할 전략
- **K-Fold 교차 검증**: 안정적 평가
- **계층적 샘플링**: 클래스 균형 보장
- **파일 기반 분할**: 데이터 누수 방지

## 📁 생성된 주요 파일들

### 모델 파일
- `cross_validation_model.pth` - 교차 검증 모델
- `specialized_model.pth` - 특화 모델
- `ensemble_model.pth` - 앙상블 모델
- `optimized_cv_model.pth` - 최적화 모델 (진행 중)

### 분석 파일
- `final_model_performance_report.json` - 최종 성능 분석
- `specialized_model_analysis_report.json` - 특화 모델 분석
- `ensemble_model_report.json` - 앙상블 모델 분석

### 시각화 파일
- `final_model_analysis.png` - 최종 모델 분석 차트
- `specialized_model_analysis.png` - 특화 모델 분석 차트
- `ensemble_model_analysis.png` - 앙상블 모델 분석 차트
- `cross_validation_analysis.png` - 교차 검증 분석 차트

### 훈련 스크립트
- `cross_validation_training.py` - 교차 검증 훈련
- `specialized_model_trainer.py` - 특화 모델 훈련
- `ensemble_model_trainer.py` - 앙상블 모델 훈련
- `optimized_cv_trainer.py` - 최적화 모델 훈련

## 💡 핵심 인사이트

### 1. 데이터 품질의 중요성
- **센서 드리프트**: Yaw 각도의 누적 오차가 성능에 큰 영향
- **노이즈 처리**: 적절한 필터링이 클래스 분리도 향상
- **클래스별 특성**: 각 클래스마다 다른 센서 의존도

### 2. 모델 복잡성 vs 성능
- **단순 모델**: 과적합 위험 낮음, 성능 한계
- **복잡 모델**: 높은 표현력, 과적합 위험
- **최적 균형**: 데이터 크기와 모델 복잡성의 조화

### 3. 평가 방법의 중요성
- **데이터 누수**: 시나리오 분할로 해결
- **과적합 감지**: Train-Val Gap 모니터링
- **안정적 평가**: K-Fold 교차 검증

### 4. 앙상블의 한계
- **성능 저하**: 약한 모델이 전체 성능을 저하시킴
- **동적 가중치**: 클래스별 성능에 따른 가중치 조정 필요
- **모델 선택**: 앙상블 구성 모델의 품질이 중요

## 🎯 현재 상태 및 다음 단계

### 현재 상태
- **최고 성능**: 77.33% (교차 검증 모델)
- **진행 중**: 최적화 모델 훈련 (목표 >80%)
- **주요 문제**: 8개 클래스의 낮은 성능

### 다음 단계 옵션
1. **최적화 모델 완성**: 현재 진행 중인 훈련 완료
2. **데이터 품질 개선**: 추가 데이터 수집 또는 센서 보정
3. **하드웨어 개선**: 지자기 센서 추가 고려
4. **실시간 시스템**: 추론 최적화 및 배포

## 🔬 기술적 도전과 해결책

### 주요 도전
1. **센서 드리프트**: 보완 필터로 부분적 해결
2. **과적합**: 다양한 정규화 기법으로 해결
3. **클래스 불균형**: 계층적 샘플링으로 해결
4. **데이터 누수**: 파일 기반 분할로 해결

### 미해결 문제
1. **일부 클래스의 낮은 성능**: 센서 한계로 인한 근본적 문제
2. **실시간 성능**: 추론 속도 최적화 필요
3. **하드웨어 의존성**: 센서 품질에 따른 성능 변동

---

**프로젝트 기간**: 약 2-3개월
**총 작업 시간**: 약 100-150시간
**생성된 코드**: 약 5,000줄
**실험 횟수**: 20+ 회
**최종 목표**: 실시간 한국 수어 인식 시스템
