#!/usr/bin/env python3
"""
Episode ë°ì´í„° ì „ìš© ì¶”ë¡  íŒŒì´í”„ë¼ì¸
ê· í˜•ì¡íŒ ëª¨ë¸ê³¼ í˜¸í™˜ë˜ëŠ” Episode ë°ì´í„° í˜•íƒœë¡œ ì¶”ë¡ 
"""

import os
import sys
import time
import torch
import torch.nn.functional as F
import numpy as np
import logging
from collections import deque
from typing import Optional, Dict, List, Union
from dataclasses import dataclass

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from models.deep_learning import DeepLearningPipeline
from training.label_mapping import KSLLabelMapper

@dataclass
class EpisodeSensorReading:
    """Episode ì„¼ì„œ ë°ì´í„°"""
    timestamp: float
    flex_data: List[float]  # 5ê°œ flex ì„¼ì„œ
    orientation_data: List[float]  # 3ê°œ orientation (pitch, roll, yaw)
    source: str = "episode"
    
    def to_array(self) -> np.ndarray:
        """numpy ë°°ì—´ë¡œ ë³€í™˜"""
        return np.concatenate([self.flex_data, self.orientation_data])

@dataclass
class EpisodeInferenceResult:
    """Episode ì¶”ë¡  ê²°ê³¼"""
    predicted_class: str
    confidence: float
    processing_time: float
    timestamp: float
    correct: bool = False
    expected_class: str = ""

class EpisodeInferencePipeline:
    """Episode ë°ì´í„° ì „ìš© ì¶”ë¡  íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, model_path: str, window_size: int = 20):
        self.model_path = model_path
        self.window_size = window_size
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ë¼ë²¨ ë§¤í¼
        self.label_mapper = KSLLabelMapper()
        self.class_names = [self.label_mapper.get_class_name(i) for i in range(self.label_mapper.get_num_classes())]
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        
        # ë°ì´í„° ë²„í¼
        self.data_buffer = deque(maxlen=window_size * 2)
        
        # ë¡œê¹…
        self.logger = logging.getLogger(__name__)
        
        print(f"ğŸš€ Episode ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"  ì¥ì¹˜: {self.device}")
        print(f"  ìœˆë„ìš° í¬ê¸°: {window_size}")
        print(f"  í´ë˜ìŠ¤ ìˆ˜: {len(self.class_names)}")
    
    def _load_model(self) -> DeepLearningPipeline:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            print(f"ğŸ“¥ ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_path}")
            
            # ëª¨ë¸ ì´ˆê¸°í™”
            model = DeepLearningPipeline(
                input_features=8,
                sequence_length=self.window_size,
                num_classes=self.label_mapper.get_num_classes(),
                hidden_dim=128,
                num_layers=2,
                dropout=0.3
            ).to(self.device)
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
            
            if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'])
            elif hasattr(checkpoint, 'eval'):
                model = checkpoint
            else:
                model.load_state_dict(checkpoint)
            
            model.eval()
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def add_sensor_data(self, flex_data: List[float], orientation_data: List[float]) -> bool:
        """ì„¼ì„œ ë°ì´í„° ì¶”ê°€"""
        try:
            # ë°ì´í„° ê²€ì¦
            if len(flex_data) != 5 or len(orientation_data) != 3:
                print(f"âš ï¸ ì˜ëª»ëœ ë°ì´í„° í¬ê¸°: flex={len(flex_data)}, orientation={len(orientation_data)}")
                return False
            
            # SensorReading ìƒì„±
            reading = EpisodeSensorReading(
                timestamp=time.time(),
                flex_data=flex_data,
                orientation_data=orientation_data
            )
            
            # ë²„í¼ì— ì¶”ê°€
            self.data_buffer.append(reading)
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def predict_single(self, expected_class: str = "") -> Optional[EpisodeInferenceResult]:
        """ë‹¨ì¼ ì¶”ë¡  ìˆ˜í–‰"""
        try:
            # ì¶©ë¶„í•œ ë°ì´í„° í™•ì¸
            if len(self.data_buffer) < self.window_size:
                return None
            
            # ìœˆë„ìš° ë°ì´í„° ìƒì„±
            window_data = self._create_window()
            
            # ì¶”ë¡  ìˆ˜í–‰
            start_time = time.time()
            prediction = self._perform_inference(window_data)
            inference_time = time.time() - start_time
            
            if prediction is None:
                return None
            
            # ì •í™•ì„± ê³„ì‚°
            is_correct = expected_class and prediction['class'] == expected_class
            
            # ê²°ê³¼ ìƒì„±
            result = EpisodeInferenceResult(
                predicted_class=prediction['class'],
                confidence=prediction['confidence'],
                processing_time=inference_time,
                timestamp=time.time(),
                correct=is_correct,
                expected_class=expected_class
            )
            
            return result
            
        except Exception as e:
            print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def _create_window(self) -> np.ndarray:
        """ì¶”ë¡ ìš© ìœˆë„ìš° ìƒì„±"""
        # ìµœê·¼ ë°ì´í„°ë¡œ ìœˆë„ìš° ìƒì„±
        recent_data = list(self.data_buffer)[-self.window_size:]
        
        # ìœˆë„ìš° ë°ì´í„°ë¥¼ 2D ë°°ì—´ë¡œ ë³€í™˜
        window_array = np.array([
            reading.to_array() for reading in recent_data
        ])
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, window_size, 8)
        window_array = window_array.reshape(1, self.window_size, 8)
        
        return window_array
    
    def _perform_inference(self, window_data: np.ndarray) -> Optional[Dict]:
        """ì‹¤ì œ ì¶”ë¡  ìˆ˜í–‰"""
        try:
            # í…ì„œ ë³€í™˜
            input_tensor = torch.FloatTensor(window_data).to(self.device)
            
            # ì¶”ë¡ 
            with torch.no_grad():
                output = self.model(input_tensor)
                
                # ì¶œë ¥ í˜•íƒœì— ë”°ë¥¸ ì²˜ë¦¬
                if isinstance(output, dict):
                    logits = output['class_logits']
                else:
                    logits = output
                
                # í™•ë¥  ê³„ì‚°
                probabilities = F.softmax(logits, dim=1)
                
                # ìµœëŒ€ í™•ë¥ ê³¼ í´ë˜ìŠ¤
                max_prob, predicted_class = torch.max(probabilities, 1)
                
                confidence = max_prob.item()
                class_idx = predicted_class.item()
                
                return {
                    'class': self.class_names[class_idx],
                    'confidence': confidence,
                    'probabilities': probabilities.cpu().numpy(),
                    'metadata': {
                        'class_index': class_idx,
                        'all_probabilities': probabilities.cpu().numpy().tolist()
                    }
                }
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None
    
    def get_performance_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            'window_size': self.window_size,
            'buffer_size': len(self.data_buffer),
            'device': str(self.device),
            'model_path': self.model_path
        }

def create_episode_inference_pipeline(model_path: str, config: Dict = None) -> EpisodeInferencePipeline:
    """Episode ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    if config is None:
        config = {}
    
    window_size = config.get('window_size', 20)
    
    return EpisodeInferencePipeline(
        model_path=model_path,
        window_size=window_size
    )
