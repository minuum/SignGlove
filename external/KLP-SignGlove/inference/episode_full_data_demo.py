#!/usr/bin/env python3
"""
ì „ì²´ Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨
600ê°œ Episode íŒŒì¼ ëª¨ë‘ ì‚¬ìš©í•œ í¬ê´„ì  í…ŒìŠ¤íŠ¸
"""

import sys
import os
import time
import json
import glob
import numpy as np
from pathlib import Path
import pandas as pd
from typing import Dict, List, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from inference.episode_inference import (
    EpisodeInferencePipeline, 
    EpisodeSensorReading, 
    create_episode_inference_pipeline
)

class EpisodeFullDataDemo:
    """ì „ì²´ Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨"""
    
    def __init__(self):
        self.pipeline = None
        self.results_log = []
        
    def setup_episode_pipeline(self):
        """Episode ë°ì´í„°ìš© ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
        print("ğŸš€ ì „ì²´ Episode ë°ì´í„° ê¸°ë°˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”")
        print("=" * 70)
        
        # ê· í˜•ì¡íŒ Episode ëª¨ë¸ ì‚¬ìš© (99.92% ì •í™•ë„)
        config = {
            'window_size': 20
        }
        self.pipeline = create_episode_inference_pipeline(
            model_path="best_balanced_episode_model.pth",
            config=config
        )
            
        print("âœ… ì „ì²´ Episode ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        stats = self.pipeline.get_performance_stats()
        print(f"ğŸ“Š ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ:")
        print(f"  - ìœˆë„ìš° í¬ê¸°: {stats['window_size']}")
        print(f"  - ë²„í¼ í¬ê¸°: {stats['buffer_size']}")
        print(f"  - ì¥ì¹˜: {stats['device']}")
        
    def load_all_episode_data(self) -> List[Dict]:
        """ì „ì²´ Episode ì„¼ì„œ ë°ì´í„° ë¡œë“œ (600ê°œ íŒŒì¼ ëª¨ë‘)"""
        print("\nğŸ“ ì „ì²´ Episode ì„¼ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        sensor_data = []
        # ëª¨ë“  Episode CSV íŒŒì¼ë“¤ ì°¾ê¸°
        data_sources = glob.glob(os.path.join("integrations/SignGlove_HW/github_unified_data", "**/episode_*.csv"), recursive=True)
        
        print(f"ğŸ“ ë°œê²¬ëœ Episode íŒŒì¼: {len(data_sources)}ê°œ")
        
        # í´ë˜ìŠ¤ë³„ íŒŒì¼ ì¹´ìš´íŠ¸
        class_file_counts = {}
        
        for data_file in data_sources:
            if os.path.exists(data_file):
                try:
                    df = pd.read_csv(data_file)
                    filename = os.path.basename(data_file)
                    
                    # Ground Truth ë¼ë²¨ ì¶”ì¶œ
                    ground_truth = None
                    for class_name in ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…', 'ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£']:
                        if f'_{class_name}_' in filename:
                            ground_truth = class_name
                            break
                    
                    if not ground_truth:
                        continue
                    
                    # í´ë˜ìŠ¤ë³„ íŒŒì¼ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                    if ground_truth not in class_file_counts:
                        class_file_counts[ground_truth] = 0
                    class_file_counts[ground_truth] += 1
                    
                    print(f"  ğŸ“„ ë¡œë“œ: {filename} ({len(df)}ê°œ ìƒ˜í”Œ) - {ground_truth}")
                    
                    # ë°ì´í„° ë³€í™˜ (Episode í˜•íƒœ)
                    class_samples = 0
                    for idx, row in df.iterrows():
                        try:
                            # Episode ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜
                            available_cols = df.columns.tolist()
                            
                            # Flex ì„¼ì„œ ì»¬ëŸ¼ ì°¾ê¸°
                            flex_cols = []
                            for i in range(1, 6):
                                flex_patterns = [f'flex{i}', f'Flex{i}', f'FLEX{i}']
                                for pattern in flex_patterns:
                                    if pattern in available_cols:
                                        flex_cols.append(pattern)
                                        break
                            
                            # Orientation ì»¬ëŸ¼ ì°¾ê¸°
                            pitch_col = None
                            roll_col = None
                            yaw_col = None
                            
                            for col in available_cols:
                                if 'pitch' in col.lower():
                                    pitch_col = col
                                elif 'roll' in col.lower():
                                    roll_col = col
                                elif 'yaw' in col.lower():
                                    yaw_col = col
                            
                            if not flex_cols or not all([pitch_col, roll_col, yaw_col]):
                                continue
                            
                            # ì„¼ì„œ ë°ì´í„° ì¶”ì¶œ
                            flex_data = [float(row[col]) for col in flex_cols]
                            orientation_data = [float(row[pitch_col]), float(row[roll_col]), float(row[yaw_col])]
                            
                            sensor_data.append({
                                'flex_data': flex_data,
                                'orientation_data': orientation_data,
                                'ground_truth': ground_truth,
                                'file': filename,
                                'row': idx
                            })
                            
                            class_samples += 1
                            
                            # íŒŒì¼ë‹¹ ìµœëŒ€ 100ê°œ ìƒ˜í”Œë¡œ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                            if class_samples >= 100:
                                break
                                
                        except Exception as e:
                            continue
                    
                    print(f"    ğŸ“Š ë³€í™˜ëœ ìƒ˜í”Œ: {class_samples}ê°œ")
                    
                except Exception as e:
                    print(f"  âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {data_file} - {e}")
                    continue
        
        print(f"\nğŸ“Š í´ë˜ìŠ¤ë³„ íŒŒì¼ ë¶„í¬:")
        for class_name in sorted(class_file_counts.keys()):
            print(f"  {class_name}: {class_file_counts[class_name]}ê°œ íŒŒì¼")
        
        print(f"\nâœ… ì´ {len(sensor_data)}ê°œ ì„¼ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        print(f"ğŸ“ˆ ë°ì´í„° ì‚¬ìš©ë¥ : {len(data_sources)}/600 = {len(data_sources)/600*100:.1f}%")
        
        return sensor_data
    
    def run_comprehensive_test(self, sensor_data: List[Dict]):
        """í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\nğŸ¯ ì „ì²´ ë°ì´í„° í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        total_tests = len(sensor_data)
        correct_predictions = 0
        class_performance = {}
        confidence_scores = []
        
        print(f"ğŸ“Š ì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        for i, data_item in enumerate(sensor_data):
            if i % 1000 == 0:
                progress = (i / total_tests) * 100
                print(f"  ì§„í–‰ë¥ : {i}/{total_tests} ({progress:.1f}%)")
            
            try:
                # íŒŒì´í”„ë¼ì¸ì— ë°ì´í„° ì¶”ê°€
                success = self.pipeline.add_sensor_data(
                    data_item['flex_data'],
                    data_item['orientation_data']
                )
                
                if not success:
                    continue
                
                # ì¶”ë¡  ì‹¤í–‰
                result = self.pipeline.predict_single(
                    expected_class=data_item['ground_truth']
                )
                
                if result is None:
                    continue
                
                # ê²°ê³¼ ë¶„ì„
                if result.correct:
                    correct_predictions += 1
                
                # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì¶”ì 
                class_name = data_item['ground_truth']
                if class_name not in class_performance:
                    class_performance[class_name] = {'total': 0, 'correct': 0}
                
                class_performance[class_name]['total'] += 1
                if result.correct:
                    class_performance[class_name]['correct'] += 1
                
                # ì‹ ë¢°ë„ ê¸°ë¡
                confidence_scores.append(result.confidence)
                
                # ê²°ê³¼ ë¡œê·¸ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¼ë¶€ë§Œ ì €ì¥)
                if i % 100 == 0:
                    self.results_log.append({
                        'file': data_item['file'],
                        'row': data_item['row'],
                        'ground_truth': data_item['ground_truth'],
                        'predicted': result.predicted_class,
                        'confidence': result.confidence,
                        'correct': result.correct,
                        'processing_time': result.processing_time
                    })
                
            except Exception as e:
                continue
        
        # ê²°ê³¼ ë¶„ì„
        overall_accuracy = (correct_predictions / total_tests) * 100 if total_tests > 0 else 0
        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0
        min_confidence = np.min(confidence_scores) if confidence_scores else 0
        max_confidence = np.max(confidence_scores) if confidence_scores else 0
        
        print(f"âœ… ì „ì²´ ë°ì´í„° í¬ê´„ì  í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {correct_predictions}ê°œ ì˜ˆì¸¡")
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì „ì²´ Episode ë°ì´í„° ì¶”ë¡  ê²°ê³¼ ë¶„ì„")
        print("=" * 60)
        print(f"ğŸ“ˆ ì „ì²´ ì„±ëŠ¥:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests:,}ê°œ")
        print(f"  ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions:,}ê°œ")
        print(f"  ì „ì²´ ì •í™•ë„: {overall_accuracy:.2f}%")
        
        print(f"\nğŸ“‹ í´ë˜ìŠ¤ë³„ ìƒì„¸ ì„±ëŠ¥:")
        print("-" * 60)
        print("í´ë˜ìŠ¤  ì´ìˆ˜     ì •í™•     ì •í™•ë„")
        print("-" * 60)
        
        for class_name in sorted(class_performance.keys()):
            stats = class_performance[class_name]
            accuracy = (stats['correct'] / stats['total']) * 100 if stats['total'] > 0 else 0
            print(f"{class_name:<4} {stats['total']:>6} {stats['correct']:>6} {accuracy:>8.1f} %")
        
        print(f"\nğŸ¯ ì‹ ë¢°ë„ ë¶„ì„:")
        print(f"  ì „ì²´ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
        print(f"  ì‹ ë¢°ë„ ë²”ìœ„: {min_confidence:.3f} ~ {max_confidence:.3f}")
        
        return overall_accuracy, class_performance
    
    def run_sample_realtime_simulation(self, sensor_data: List[Dict]):
        """ìƒ˜í”Œ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ (ì „ì²´ ë°ì´í„°ì—ì„œ ì¼ë¶€ë§Œ)"""
        print(f"\nğŸ® ìƒ˜í”Œ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜ (í´ë˜ìŠ¤ë‹¹ 5ê°œ íŒŒì¼)")
        print("=" * 60)
        
        # í´ë˜ìŠ¤ë³„ë¡œ ìƒ˜í”Œ ì„ íƒ (í´ë˜ìŠ¤ë‹¹ 5ê°œ íŒŒì¼ì—ì„œ ê°ê° 10ê°œ ìƒ˜í”Œ)
        class_samples = {}
        for data_item in sensor_data:
            class_name = data_item['ground_truth']
            if class_name not in class_samples:
                class_samples[class_name] = []
            if len(class_samples[class_name]) < 50:  # í´ë˜ìŠ¤ë‹¹ 50ê°œ ìƒ˜í”Œ
                class_samples[class_name].append(data_item)
        
        total_tests = 0
        correct_tests = 0
        
        for class_name in sorted(class_samples.keys()):
            samples = class_samples[class_name]
            if not samples:
                continue
                
            print(f"\nğŸ” {class_name} ìƒ˜í”Œ í…ŒìŠ¤íŠ¸:")
            class_correct = 0
            
            # ë²„í¼ ì´ˆê¸°í™”
            self.pipeline.data_buffer.clear()
            
            # ì—°ì†ì ìœ¼ë¡œ ë°ì´í„° ì¶”ê°€í•˜ë©´ì„œ ì¶”ë¡ 
            for i, sample in enumerate(samples):
                try:
                    # íŒŒì´í”„ë¼ì¸ì— ë°ì´í„° ì¶”ê°€
                    success = self.pipeline.add_sensor_data(
                        sample['flex_data'],
                        sample['orientation_data']
                    )
                    
                    if not success:
                        continue
                    
                    # ìœˆë„ìš°ê°€ ì¶©ë¶„íˆ ìŒ“ì¸ í›„ë¶€í„° ì¶”ë¡  ì‹œì‘
                    if len(self.pipeline.data_buffer) >= self.pipeline.window_size:
                        # ì¶”ë¡  ì‹¤í–‰
                        result = self.pipeline.predict_single(
                            expected_class=sample['ground_truth']
                        )
                        
                        if result is None:
                            continue
                        
                        if result.correct:
                            class_correct += 1
                            correct_tests += 1
                        
                        total_tests += 1
                        
                        # 10ê°œ ìƒ˜í”Œë§ˆë‹¤ ê²°ê³¼ ì¶œë ¥
                        if total_tests % 10 == 0:
                            print(f"    ... ì§„í–‰ë¥ : {total_tests}ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                    
                except Exception as e:
                    continue
            
            class_accuracy = (class_correct / len(samples)) * 100 if samples else 0
            print(f"  ğŸ“Š {class_name} ì •í™•ë„: {class_accuracy:.1f}% ({class_correct}/{len(samples)})")
        
        overall_accuracy = (correct_tests / total_tests) * 100 if total_tests > 0 else 0
        print(f"\nğŸ¯ ì „ì²´ ìƒ˜í”Œ ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"  ì •í™•í•œ ì˜ˆì¸¡: {correct_tests}ê°œ")
        print(f"  ì „ì²´ ì •í™•ë„: {overall_accuracy:.2f}%")
        
        return overall_accuracy
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        results = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'model': 'best_balanced_episode_model.pth',
            'pipeline': 'EpisodeInferencePipeline Full Data',
            'results': self.results_log
        }
        
        with open('episode_full_data_demo_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print("âœ… ê²°ê³¼ ì €ì¥: episode_full_data_demo_results.json")
    
    def run_demo(self):
        """ì „ì²´ ë°ëª¨ ì‹¤í–‰"""
        print("ğŸš€ ì „ì²´ Episode ë°ì´í„° ê¸°ë°˜ ì‹¤ì‹œê°„ ì¶”ë¡  ë°ëª¨ ì‹œì‘")
        print("=" * 70)
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        self.setup_episode_pipeline()
        
        # ì „ì²´ ë°ì´í„° ë¡œë“œ
        sensor_data = self.load_all_episode_data()
        
        if not sensor_data:
            print("âŒ ë¡œë“œëœ ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì „ì²´ ë°ì´í„° í¬ê´„ì  í…ŒìŠ¤íŠ¸
        overall_accuracy, class_performance = self.run_comprehensive_test(sensor_data)
        
        # ìƒ˜í”Œ ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        realtime_accuracy = self.run_sample_realtime_simulation(sensor_data)
        
        # ê²°ê³¼ ì €ì¥
        self.save_results()
        
        print(f"\nğŸ‰ ì „ì²´ Episode ë°ì´í„° ì¶”ë¡  ë°ëª¨ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥:")
        print(f"  - ì „ì²´ ë°ì´í„° í…ŒìŠ¤íŠ¸: {overall_accuracy:.2f}%")
        print(f"  - ìƒ˜í”Œ ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜: {realtime_accuracy:.2f}%")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    demo = EpisodeFullDataDemo()
    demo.run_demo()

if __name__ == "__main__":
    main()
