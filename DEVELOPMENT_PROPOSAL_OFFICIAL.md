# 개발제안서

## 기본 정보

**팀 명**: SignGlove Team

**APP명**: SignTalk (사인톡)

**분야 (대주제)**:
☑ 분야 1 (디지털 포용)     
☐ 분야 2 (자립생활 지원)

**중주제 (택1)**:
☑ ① 디지털 기기/기술 활용 보조
☐ ② 디지털 컨텐츠 제작 지원
☐ ③ 정보 접근성 향상 
☐ ④ 교육 및 훈련 
☐ ⑤ 기타 자유주제

**사용가능 장애유형 (중복선택 가능)**:
☐ 지체장애 ☐ 뇌병변장애 ☐ 시각장애 ☑ 청각장애 ☑ 언어장애 ☐ 지적장애
☐ 자폐성 장애 ☐ 정신장애 ☐ 신장장애 ☐ 심장장애 ☐ 호흡기장애 ☐ 간장애
☐ 안면장애 ☐ 장루·요루 장애 ☐ 뇌전증 장애

**활용기술**:
☑ AI(인공지능) ☐ 빅데이터 ☐ 가상현실(VR) 
☐ 증강현실(AR) ☑ 음성 또는 동작인식 ☑ 기타(센서 융합, 웨어러블)

## 1. 기획의도 및 필요성

### 청각장애인 소통 현황과 심각성

국내 청각장애인 약 25.5만명(언어장애 포함 27.2만명)이 일상생활에서 의사소통 장벽으로 어려움을 겪고 있습니다. 특히 65세 이상 고령 청각장애인 비중이 73.2%로 증가하면서 소통 지원 필요성이 더욱 커지고 있습니다.

### 소통 인프라의 절대 부족

전국 수어통역센터는 192개소에 불과하며, 국가공인 수어통역사는 1,134명으로 27만 청각장애인 대비 절대 부족한 상황입니다. 이로 인해 의료기관, 관공서, 교육기관에서 수어통역 서비스를 받지 못하는 경우가 빈발하고 있습니다.

### 기존 의사소통 도구의 구조적 한계

**비장애인 중심의 준비 부담**:
현재 청각장애인용 의사소통 도구들은 대부분 비장애인의 적극적인 참여나 준비를 필요로 합니다[1]:
- 수어 통역 서비스: 비장애인이 통역사를 호출하고 비용을 부담해야 함
- 수어 학습 프로그램: 비장애인이 수어를 배우는 시간과 노력 투자 필요
- 음성-문자 변환 앱: 비장애인이 앱을 다운로드하고 사용법을 익혀야 함
- 전문 통신 장비: 비장애인 측에서 장비 설치 및 운영 준비 필요

이러한 구조는 청각장애인에게 "비장애인의 호의와 준비에 의존해야 하는" 추가적인 심리적 부담을 가중시키고 있습니다.

**소통 주도권의 불균형**:
기존 도구들은 청각장애인이 소통을 주도적으로 시작하기 어려운 구조로, 비장애인의 준비 상태에 따라 의사소통 가능 여부가 결정되는 한계가 있습니다.

### 일상생활 접근성의 현실적 제약

**즉시성 부족**: 응급상황이나 즉석 만남에서 통역사 호출이나 앱 설치를 기다릴 수 없는 상황 빈발[2]
**경제적 부담**: 개인이 매번 통역 서비스 비용을 부담하기 어려운 현실
**프라이버시 제약**: 개인적 대화나 민감한 내용을 제3자(통역사)를 통해 전달해야 하는 부담

### 우리 팀의 차별화된 접근 방식

**장애 당사자 중심의 자립적 소통 도구**:
SignGlove는 청각장애인과 언어장애인이 비장애인의 추가적인 준비나 참여 없이도 주도적으로 의사소통을 시작할 수 있는 전용 솔루션입니다.

**개발 목표**:
1. 청각장애인이 글러브 착용만으로 즉시 사용 가능한 독립적 소통 도구
2. 비장애인의 사전 준비나 학습 없이도 자연스러운 의사소통 지원
3. 실시간 KSL → 음성/텍스트 변환으로 즉시성과 프라이버시 보장
4. 경제적 부담 없는 개인 소유 디바이스로 언제든 사용 가능

## 2. 국내·외 유사 개발물 사례 비교 및 차이점

### 해외 주요 제품 분석

**SignAll (헝가리)**:
- ASL(미국 수어) 기반 웨어러블 장갑
- 인식률 약 70% 수준, 복합 문장 번역 한계

**Signily (미국)**:
- 컴퓨터 비전 기반 모바일 앱
- 조명/배경 환경 의존성 높음 (인식률 40-80% 편차)

**Google MediaPipe**:
- 손동작 추적 기술 특화
- 실제 수어 번역 기능 부족

### 국내 서비스 현황

**국립국어원 한국수어사전**:
- 일방향 검색만 가능, 실시간 번역 부재

**손말이음 앱**:
- 단어 수준 번역, 문장 단위 소통 어려움

### SignTalk의 차별점

1. **환경 독립적 인식**: 플렉스 센서 + IMU 센서 융합으로 조명/배경 영향 최소화[3]
2. **KSL 특화**: 한국어 수어 34개 클래스 체계적 정의 및 문법 구조 반영[4]
3. **실시간 처리**: 104Hz 센서 데이터 기반 즉시 번역
4. **웨어러블 편의성**: 글러브 착용만으로 간편 사용, 고령층 접근성 향상

## 3. 서비스 기능 및 활용기술 설명

### 시스템 아키텍처

**하드웨어 구성**:
- Arduino Nano 33 IoT (WiFi 내장 메인 컨트롤러)
- LSM6DS3 IMU 센서 (6축 가속도계/자이로스코프, 104Hz)
- 플렉스 센서 5개 (손가락별 굽힘 각도 측정)
- 통신: WiFi TCP + UART 115200bps 백업

**서버 시스템**:
- FastAPI 기반 실시간 데이터 수집/처리 서버
- Butterworth 필터 노이즈 제거 및 정규화 전처리
- CNN+LSTM 하이브리드 딥러닝 모델
- 한국어 TTS 음성 합성 엔진

### 메인 서비스 기능

#### 1. 실시간 수어 인식 및 번역
- **입력**: 플렉스 센서 5개 + IMU 센서 데이터 (104Hz)
- **처리**: 시계열 패턴 분석을 통한 KSL 분류
- **출력**: 텍스트 표시 + 한국어 음성 합성

#### 2. KSL 34개 클래스 지원
- 자음 14개: ㄱ, ㄴ, ㄷ, ㄹ, ㅁ, ㅂ, ㅅ, ㅇ, ㅈ, ㅊ, ㅋ, ㅌ, ㅍ, ㅎ
- 모음 10개: ㅏ, ㅓ, ㅗ, ㅜ, ㅡ, ㅣ, ㅑ, ㅕ, ㅛ, ㅠ  
- 숫자 10개: 0-9

#### 3. 센서 퓨전 기반 정밀 인식
- Madgwick Filter 적용으로 손목 방향 모호함 해결
- 신뢰도 기반 판단 (0-1 점수)으로 오인식 최소화
- 드리프트 보정 및 누적 오차 제거

### 핵심 기술

**AI 기술**:
- CNN (1D Convolution): 센서 데이터 특징 추출
- LSTM: 시계열 패턴 학습 및 문맥 이해
- Attention 메커니즘: 중요 시점 가중치 부여

**센서 융합 기술**:
- 플렉스 센서: 손가락 굽힘각 (0-180도, 12bit 해상도)
- IMU 센서: 가속도 ±4g, 자이로 ±2000dps
- 실시간 처리: 20-50ms 간격 데이터 수집

### 장애인 복지와의 연관성

1. **소통권 보장**: 수어를 모르는 사람과도 자유로운 의사소통 가능
2. **사회 참여 확대**: 의료, 교육, 취업 분야 접근성 향상
3. **자립생활 지원**: 응급상황 대응 및 일상생활 편의성 제고
4. **디지털 포용**: 고령 청각장애인도 쉽게 사용할 수 있는 웨어러블 인터페이스
5. **소통 주도권 회복**: 비장애인의 준비에 의존하지 않는 능동적 의사소통 실현
6. **심리적 부담 경감**: 제3자 개입 없는 직접적이고 프라이빗한 소통 지원

## 4. 상용화 및 구체화 전략

### 3단계 시장 진입 전략

**1단계: 신뢰도 검증 (2025년 8-12월)**
- 전국 주요 청각장애인 복지관 10개소 파일럿 테스트
- 30명 베타 테스터 그룹 운영, 6개월 실사용 검증
- 목표: 사용자 만족도 85% 이상, 일상 사용률 70% 이상

**2단계: 제도권 진입 (2026년 1-6월)**
- 보건복지부 장애인 보조기구 품목 등재 신청
- 국민건강보험공단 급여 적용 협의
- 목표: 본인부담금 20% 수준 (50만원 → 10만원)

**3단계: 전국 확산 (2026년 7월-2027년)**
- 의료기관, 관공서 의무 배치 시범사업 참여
- 동남아시아 수어 시장 진출 준비
- 목표: 연 매출 100억원, 시장 점유율 4.4%

### 수익 모델

**다각화된 수익 구조**:
1. 하드웨어 판매 (60%): 글러브 패키지 50만원 × 연 12,000대
2. 구독 서비스 (25%): 클라우드 AI 서비스 월 1만원
3. B2B 라이센싱 (15%): 기업/기관 대상 API 제공

### 전략적 파트너십

**정부 기관**: 한국장애인개발원, 국립특수교육원
**민간 기업**: 삼성전자(하드웨어), 네이버(AI), 카카오(플랫폼)
**사용자 단체**: 한국농아인협회, 전국 청각장애인 복지관

## 5. 리스크 및 해결방안

### 기술적 리스크

**하드웨어 제작 문제**:
- 리스크: 플렉스 센서 납땜 연결 불안정
- 해결방안: pin header → resistor → cable 연결구조, 단계적 테스트

**센서 데이터 모호함**:
- 리스크: IMU 센서 방향 판단 실패
- 해결방안: Madgwick Filter 센서퓨전으로 신뢰도 기반 판단

**AI 모델 성능**:
- 리스크: 실제 KSL 데이터 부족으로 성능 예측 어려움
- 해결방안: ASL→KSL 전이학습, 데이터 증강 기법 적용

### 시장 진입 리스크

**경제적 접근성**:
- 리스크: 하드웨어 비용으로 인한 높은 기기 가격
- 해결방안: 정부 보조기구 등재, 렌탈 서비스 모델 도입

**사용자 적응**:
- 리스크: 고령층의 웨어러블 기기 적응 어려움
- 해결방안: 단순 인터페이스 설계, 복지관 교육 프로그램 운영

## 6. 개발 일정

| 구분 | 8월 | 9월 | 10월 | 11월 |
|------|-----|-----|------|------|
| **페이지 레이아웃 설계** | 하드웨어 설계<br/>센서 배치 최적화 | 사용자 인터페이스<br/>접근성 고려 설계 | - | - |
| **개발 진행** | 센서 퓨전 알고리즘<br/>기본 데이터 수집 | CNN+LSTM 모델 학습<br/>실시간 추론 엔진 | 개인화 적응 기능<br/>성능 최적화 | 시스템 통합<br/>배포 준비 |
| **오류 수정** | 플렉스 센서 연결<br/>통신 안정성 | 모델 정확도 향상<br/>노이즈 필터링 | 실시간 처리 최적화<br/>메모리 관리 | 사용성 개선<br/>접근성 강화 |
| **테스트** | 하드웨어 동작 검증<br/>센서 정확도 측정 | 실사용자 테스트<br/>피드백 수집 | 복지관 파일럿 테스트<br/>성능 벤치마킹 | 최종 사용자 검수<br/>상용화 준비 |

## 7. 장애인 특성 및 욕구를 반영한 개발 계획

### 당사자 참여형 개발 프로세스

**사용자 중심 설계**:
- 개발 초기부터 청각장애인 당사자를 자문위원으로 참여
- 매주 정기 사용자 인터뷰를 통한 요구사항 수집
- 실제 수어 사용 환경에서의 테스트 및 피드백 반영

**다양성 고려**:
- 지역별 수어 방언 및 개인적 표현 습관 반영
- 연령대별 수어 사용 패턴 분석 (특히 65세 이상 고령층)
- 표준 수어뿐만 아니라 일상 자연스러운 표현 포함

### 접근성 우선 설계

**감각적 특성 고려**:
- 시각적 피드백: 명확한 텍스트 표시 및 상태 인디케이터
- 촉각적 피드백: 진동 알림으로 시스템 상태 전달
- 직관적 조작: 최소한의 버튼으로 핵심 기능 접근

**사용 편의성**:
- 한 손 사용 제약 고려한 글러브 설계
- 간단한 착용 방식으로 자립적 사용 가능
- 배터리 6시간 이상 연속 사용 지원

### 지속적 개선 체계

**실시간 피드백 수집**:
- 앱 내 간편한 피드백 기능 구현
- 사용 중 발생하는 오인식 케이스 자동 수집
- 월 단위 사용 패턴 분석 및 업데이트 반영

**커뮤니티 기반 개선**:
- 청각장애인 사용자 커뮤니티 구축
- 수어 패턴 크라우드소싱을 통한 데이터 품질 향상
- 지역 복지관과 연계한 정기 워크숍 개최

---

## 참가자 이력사항

### 팀원 1 - 이민우(팀장)
**학력**: 2022. ~ 2025. 강남대학교 인공지능전공

**기술**: 
- Back-end: Python, FastAPI
- Cloud: Google Cloud
- Data: Pandas, 실시간 데이터 처리

**프로젝트**: 
1. SignGlove 실시간 센서 데이터 수집 시스템 구축
   - FastAPI 기반 서버 개발 및 데이터 파이프라인 구축
2. Mobile VLA 관련 프로젝트 진행 및 작성 중
   - 모바일 환경 최적화 AI 모델 연구

### 팀원 2 - 양동건(하드웨어 개발)
**학력**: 2020. ~ 2025. 강남대학교 소프트웨어전공

**기술**:
- Embedded: Arduino, C/C++, WiFi/UART 통신
- Hardware: LSM6DS3 센서, 플렉스 센서
- Signal Processing: 실시간 신호 처리

**프로젝트**:
1. 웨어러블 센서 융합 시스템 개발
   - 5개 플렉스 센서 + 6축 IMU 센서 통합
2. 무선 데이터 전송 시스템 구축
   - WiFi/UART 통신 프로토콜 구현

### 팀원 3 - YUBEEN(ML 학습 모델)
**학력**: 2020. ~ 2025. 강남대학교 소프트웨어전공

**기술**:
- Machine Learning: TensorFlow, PyTorch
- Deep Learning: CNN, LSTM, Transformer
- Data Processing: Python, 시계열 데이터 분석

**프로젝트**:
1. 한국어 수어(KSL) AI 모델 개발
   - CNN+LSTM 하이브리드 아키텍처 설계
   - 34개 KSL 클래스 분류 모델 훈련
2. 센서 데이터 기반 패턴 인식 시스템
   - 실시간 수어 동작 인식 알고리즘 구현

### 팀원 4 - 정재연(데이터 분석)
**학력**: 2024. ~ 2025. 강남대학교 인공지능전공

**기술**:
- Data Science: Python, 통계 분석
- ML/AI: 머신러닝 모델링, 데이터 전처리
- Analysis: 센서 데이터 분석, 성능 평가

**프로젝트**:
1. 수어 데이터셋 구축 및 품질 관리
   - KSL 34개 클래스 데이터 수집 체계 설계
   - 센서 데이터 정확도 검증 시스템 개발
2. 모델 성능 분석 및 최적화
   - 인식 정확도 향상을 위한 데이터 증강 기법 적용

---

## 참고문헌

[1] kiss.kstudy.com. "청각장애인을 위한 의사소통 도구들은 주로 비장애인이 준비해야 할 사항이 많아 사용에 어려움이 있습니다. 예를 들어, 수어 통역 서비스는 통역사의 부재 시 이용이 어렵고, 문자 통역 서비스는 실시간성이 부족하여 원활한 소통에 한계가 있습니다." Available: https://kiss.kstudy.com/Detail/Ar?key=3849767

[2] kiss.kstudy.com. "문자 통역 서비스는 실시간성이 부족하여 원활한 소통에 한계가 있습니다." Available: https://kiss.kstudy.com/Detail/Ar?key=3849767

[3] 현재 수어를 텍스트나 음성으로 변환하는 기술은 주로 카메라 기반의 영상 인식을 활용하고 있으나, 조명, 배경, 카메라 각도 등의 환경적 요인에 민감하여 정확도에 한계가 있음. 센서 기반의 접근 방식을 채택하여 환경적 제약을 최소화하고, 보다 안정적이고 정확한 수어 인식을 가능하게 함.

[4] 기존의 수어 인식 시스템은 주로 영어 수어(ASL)에 집중되어 있어 한국 수어(KSL)를 지원하는 기술이 부족한 실정임.

[5] kci.go.kr. "최근 연구에 따르면 블루투스 기반의 모바일 애플리케이션이 청각장애인과 비장애인 간의 의사소통에 효과적임이 입증되었습니다." Available: https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002183984
