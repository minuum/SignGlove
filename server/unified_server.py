#!/usr/bin/env python3
"""
SignGlove í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì„œë²„
ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ êµ¬ì¡°ì™€ ì—°ë™ëœ ì‹¤í—˜ ê´€ë¦¬ ë° ë°ì´í„° ìˆ˜ì§‘ ì„œë²„

ì—­í•  ë¶„ë‹´:
- ì´ë¯¼ìš°: ì„œë²„ êµ¬ì¶•, ë°ì´í„° ì €ì¥, ì‹¤í—˜ ê´€ë¦¬
- ì–‘ë™ê±´: ì•„ë‘ì´ë…¸ íŒì›¨ì–´, UART/WiFi í†µì‹ , í´ë¼ì´ì–¸íŠ¸
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uvicorn
from datetime import datetime
import logging
import asyncio
import json
from pathlib import Path
import pandas as pd

from .models.sensor_data import SensorData, SignGestureData
from .data_validation import DataValidator
from .ksl_classes import ksl_manager, KSLCategory
from .preprocessing import SensorPreprocessor
from .inference_engine import get_inference_engine, InferenceResult
from .tts_engine import get_tts_engine, speak_ksl_async
from .performance_monitor import get_performance_monitor, capture_inference_metrics

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('unified_server.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="SignGlove í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì„œë²„",
    description="ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ì ìš©ëœ ìˆ˜ì–´ ë°ì´í„° ìˆ˜ì§‘ ë° ì‹¤í—˜ ê´€ë¦¬ ì„œë²„",
    version="2.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ (ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œìš©)
app.mount("/static", StaticFiles(directory="static"), name="static")


class UnifiedDataManager:
    """í†µí•© ë°ì´í„° ê´€ë¦¬ì"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.setup_directories()
        self.load_config()
        self.current_session = None
        self.current_experiment = None
        self.collected_samples = []
        
    def setup_directories(self):
        """ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        self.data_root = Path("data")
        
        self.directories = {
            'raw': self.data_root / "raw",
            'processed': self.data_root / "processed", 
            'interim': self.data_root / "interim",
            'unified': self.data_root / "unified",
            'splits': self.data_root / "splits",
            'metadata': self.data_root / "metadata",
            'stats': self.data_root / "stats"
        }
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in self.directories.values():
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # í´ë˜ìŠ¤ë³„ í•˜ìœ„ ë””ë ‰í† ë¦¬
        categories = ['consonant', 'vowel', 'number']
        for category in categories:
            (self.directories['raw'] / category).mkdir(exist_ok=True)
            (self.directories['processed'] / category).mkdir(exist_ok=True)
    
    def load_config(self):
        """ì‹¤í—˜ ì„¤ì • ë¡œë“œ"""
        config_file = self.directories['metadata'] / "experiment_config.json"
        
        default_config = {
            'target_classes': {
                'consonant': ['ã„±', 'ã„´', 'ã„·', 'ã„¹', 'ã…', 'ã…‚', 'ã……', 'ã…‡', 'ã…ˆ', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…'],
                'vowel': ['ã…', 'ã…‘', 'ã…“', 'ã…•', 'ã…—', 'ã…›', 'ã…œ', 'ã… ', 'ã…¡', 'ã…£'],
                'number': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
            },
            'target_samples_per_class': 60,
            'measurement_duration': 5,
            'sampling_rate': 20,
            'train_ratio': 0.7,
            'val_ratio': 0.15,
            'test_ratio': 0.15
        }
        
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        else:
            self.config = default_config
            self.save_config()
    
    def save_config(self):
        """ì„¤ì • ì €ì¥"""
        config_file = self.directories['metadata'] / "experiment_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def get_class_category(self, class_label: str) -> str:
        """í´ë˜ìŠ¤ ì¹´í…Œê³ ë¦¬ ë°˜í™˜"""
        for category, classes in self.config['target_classes'].items():
            if class_label in classes:
                return category
        return "unknown"


# ì „ì—­ ë°ì´í„° ë§¤ë‹ˆì €
data_manager = UnifiedDataManager()
data_validator = DataValidator()
preprocessor = SensorPreprocessor()
inference_engine = get_inference_engine()
tts_engine = get_tts_engine()
performance_monitor = get_performance_monitor()


# API ëª¨ë¸ ì •ì˜
class ExperimentSession(BaseModel):
    """ì‹¤í—˜ ì„¸ì…˜ ëª¨ë¸"""
    session_id: str
    performer_id: str = "default_performer"
    class_label: str
    category: str
    target_samples: int = 60
    duration_per_sample: int = 5
    sampling_rate: int = 20
    storage_strategy: str = "both"  # individual, unified, both
    notes: Optional[str] = None


class ExperimentStatus(BaseModel):
    """ì‹¤í—˜ ìƒíƒœ ëª¨ë¸"""
    session_id: Optional[str]
    class_label: Optional[str]
    current_sample: int = 0
    target_samples: int = 0
    is_collecting: bool = False
    samples_collected: int = 0
    timestamp: datetime


class DataResponse(BaseModel):
    """ë°ì´í„° ì‘ë‹µ ëª¨ë¸"""
    success: bool
    message: str
    session_id: Optional[str] = None
    sample_id: Optional[int] = None
    timestamp: datetime


class ServerStats(BaseModel):
    """ì„œë²„ í†µê³„ ëª¨ë¸"""
    total_sessions: int
    total_samples: int
    classes_collected: List[str]
    disk_usage: Dict[str, int]
    uptime: str


# ===== API ì—”ë“œí¬ì¸íŠ¸ =====

@app.get("/", response_class=JSONResponse)
async def root():
    """ì„œë²„ ë£¨íŠ¸"""
    return {
        "message": "SignGlove í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì„œë²„",
        "version": "2.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/status", response_model=ExperimentStatus)
async def get_server_status():
    """ì„œë²„ ìƒíƒœ ì¡°íšŒ"""
    return ExperimentStatus(
        session_id=data_manager.current_session.session_id if data_manager.current_session else None,
        class_label=data_manager.current_experiment.get('class_label') if data_manager.current_experiment else None,
        current_sample=len(data_manager.collected_samples),
        target_samples=data_manager.current_experiment.get('target_samples', 0) if data_manager.current_experiment else 0,
        is_collecting=data_manager.current_session is not None,
        samples_collected=len(data_manager.collected_samples),
        timestamp=datetime.now()
    )


@app.post("/experiment/start", response_model=DataResponse)
async def start_experiment(session: ExperimentSession):
    """ì‹¤í—˜ ì„¸ì…˜ ì‹œì‘"""
    try:
        # ì„¸ì…˜ ID ìƒì„±
        if not session.session_id:
            session.session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # í´ë˜ìŠ¤ ì¹´í…Œê³ ë¦¬ í™•ì¸
        category = data_manager.get_class_category(session.class_label)
        if category == "unknown":
            raise HTTPException(
                status_code=400,
                detail=f"ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤: {session.class_label}"
            )
        
        # í˜„ì¬ ì„¸ì…˜ ì„¤ì •
        data_manager.current_session = session
        data_manager.current_experiment = {
            'session_id': session.session_id,
            'class_label': session.class_label,
            'category': category,
            'target_samples': session.target_samples,
            'duration_per_sample': session.duration_per_sample,
            'sampling_rate': session.sampling_rate,
            'storage_strategy': session.storage_strategy,
            'start_time': datetime.now(),
            'performer_id': session.performer_id
        }
        data_manager.collected_samples = []
        
        logger.info(f"ì‹¤í—˜ ì„¸ì…˜ ì‹œì‘: {session.session_id} - í´ë˜ìŠ¤: {session.class_label}")
        
        return DataResponse(
            success=True,
            message=f"ì‹¤í—˜ ì„¸ì…˜ ì‹œì‘ë¨: {session.class_label}",
            session_id=session.session_id,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        logger.error(f"ì‹¤í—˜ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/experiment/stop", response_model=DataResponse)
async def stop_experiment():
    """ì‹¤í—˜ ì„¸ì…˜ ì¢…ë£Œ"""
    try:
        if not data_manager.current_session:
            raise HTTPException(status_code=400, detail="ì§„í–‰ ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
        
        session_id = data_manager.current_session.session_id
        
        # ìˆ˜ì§‘ëœ ë°ì´í„° ìµœì¢… ì €ì¥
        if data_manager.collected_samples:
            await save_experiment_data()
        
        # ì„¸ì…˜ ì¢…ë£Œ
        data_manager.current_session = None
        data_manager.current_experiment = None
        data_manager.collected_samples = []
        
        logger.info(f"ì‹¤í—˜ ì„¸ì…˜ ì¢…ë£Œ: {session_id}")
        
        return DataResponse(
            success=True,
            message="ì‹¤í—˜ ì„¸ì…˜ ì¢…ë£Œë¨",
            session_id=session_id,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        logger.error(f"ì‹¤í—˜ ì¢…ë£Œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/data/sensor", response_model=DataResponse)
async def collect_sensor_data(sensor_data: SensorData, background_tasks: BackgroundTasks):
    """
    ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ (ì–‘ë™ê±´ íŒ€ì›ì´ ë³´ë‚´ëŠ” ë°ì´í„°ë¥¼ ë°›ìŒ)
    """
    try:
        # ì§„í–‰ ì¤‘ì¸ ì‹¤í—˜ í™•ì¸
        if not data_manager.current_session:
            raise HTTPException(status_code=400, detail="ì§„í–‰ ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤. /experiment/startë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # ë°ì´í„° ê²€ì¦
        validation_result = data_validator.validate_sensor_data(sensor_data)
        if not validation_result.is_valid:
            raise HTTPException(
                status_code=400,
                detail=f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {validation_result.error_message}"
            )
        
        # í˜„ì¬ ì„¸ì…˜ì— ë°ì´í„° ì¶”ê°€
        data_manager.collected_samples.append(sensor_data)
        
        sample_count = len(data_manager.collected_samples)
        logger.info(f"ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘: {sensor_data.device_id} - ìƒ˜í”Œ {sample_count}")
        
        return DataResponse(
            success=True,
            message="ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ë¨",
            session_id=data_manager.current_session.session_id,
            sample_id=sample_count,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        logger.error(f"ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/sample/complete", response_model=DataResponse)
async def complete_sample():
    """í˜„ì¬ ìƒ˜í”Œ ì™„ë£Œ ì²˜ë¦¬"""
    try:
        if not data_manager.current_session:
            raise HTTPException(status_code=400, detail="ì§„í–‰ ì¤‘ì¸ ì‹¤í—˜ì´ ì—†ìŠµë‹ˆë‹¤")
        
        if not data_manager.collected_samples:
            raise HTTPException(status_code=400, detail="ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê°œë³„ ìƒ˜í”Œ ì €ì¥
        await save_current_sample()
        
        sample_count = len(data_manager.collected_samples)
        target_samples = data_manager.current_experiment['target_samples']
        
        return DataResponse(
            success=True,
            message=f"ìƒ˜í”Œ ì™„ë£Œ ({sample_count}/{target_samples})",
            session_id=data_manager.current_session.session_id,
            sample_id=sample_count,
            timestamp=datetime.now()
        )
        
    except Exception as e:
        logger.error(f"ìƒ˜í”Œ ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


async def save_current_sample():
    """í˜„ì¬ ìˆ˜ì§‘ëœ ìƒ˜í”Œ ì €ì¥"""
    if not data_manager.current_experiment or not data_manager.collected_samples:
        return
    
    try:
        experiment = data_manager.current_experiment
        samples = data_manager.collected_samples
        
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sample_idx = len(samples) // experiment['sampling_rate'] // experiment['duration_per_sample']
        filename = f"{experiment['class_label']}_sample_{sample_idx:03d}_{timestamp}"
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì €ì¥ ê²½ë¡œ
        category = experiment['category']
        raw_dir = data_manager.directories['raw'] / category
        
        # CSV ì €ì¥
        csv_file = raw_dir / f"{filename}.csv"
        
        import csv
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = [
                'timestamp', 'device_id', 'flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5',
                'gyro_x', 'gyro_y', 'gyro_z', 'accel_x', 'accel_y', 'accel_z',
                'battery_level', 'signal_strength'
            ]
            
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for sensor_data in samples:
                row = {
                    'timestamp': sensor_data.timestamp.isoformat(),
                    'device_id': sensor_data.device_id,
                    'flex_1': sensor_data.flex_sensors.flex_1,
                    'flex_2': sensor_data.flex_sensors.flex_2,
                    'flex_3': sensor_data.flex_sensors.flex_3,
                    'flex_4': sensor_data.flex_sensors.flex_4,
                    'flex_5': sensor_data.flex_sensors.flex_5,
                    'gyro_x': sensor_data.gyro_data.gyro_x,
                    'gyro_y': sensor_data.gyro_data.gyro_y,
                    'gyro_z': sensor_data.gyro_data.gyro_z,
                    'accel_x': sensor_data.gyro_data.accel_x,
                    'accel_y': sensor_data.gyro_data.accel_y,
                    'accel_z': sensor_data.gyro_data.accel_z,
                    'battery_level': sensor_data.battery_level,
                    'signal_strength': sensor_data.signal_strength
                }
                writer.writerow(row)
        
        logger.info(f"ìƒ˜í”Œ ì €ì¥ ì™„ë£Œ: {csv_file.name}")
        
    except Exception as e:
        logger.error(f"ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")


async def save_experiment_data():
    """ì‹¤í—˜ ì™„ë£Œ ì‹œ í†µí•© ë°ì´í„° ì €ì¥"""
    if not data_manager.current_experiment or not data_manager.collected_samples:
        return
    
    try:
        experiment = data_manager.current_experiment
        samples = data_manager.collected_samples
        
        # í†µí•© íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        class_label = experiment['class_label']
        
        unified_file = data_manager.directories['unified'] / f"{class_label}_unified_{timestamp}.csv"
        
        import csv
        with open(unified_file, 'w', newline='', encoding='utf-8') as f:
            fieldnames = [
                'sample_id', 'timestamp', 'device_id', 'class_label', 'category',
                'flex_1', 'flex_2', 'flex_3', 'flex_4', 'flex_5',
                'gyro_x', 'gyro_y', 'gyro_z', 'accel_x', 'accel_y', 'accel_z',
                'battery_level', 'signal_strength'
            ]
            
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for sample_id, sensor_data in enumerate(samples):
                row = {
                    'sample_id': sample_id,
                    'timestamp': sensor_data.timestamp.isoformat(),
                    'device_id': sensor_data.device_id,
                    'class_label': class_label,
                    'category': experiment['category'],
                    'flex_1': sensor_data.flex_sensors.flex_1,
                    'flex_2': sensor_data.flex_sensors.flex_2,
                    'flex_3': sensor_data.flex_sensors.flex_3,
                    'flex_4': sensor_data.flex_sensors.flex_4,
                    'flex_5': sensor_data.flex_sensors.flex_5,
                    'gyro_x': sensor_data.gyro_data.gyro_x,
                    'gyro_y': sensor_data.gyro_data.gyro_y,
                    'gyro_z': sensor_data.gyro_data.gyro_z,
                    'accel_x': sensor_data.gyro_data.accel_x,
                    'accel_y': sensor_data.gyro_data.accel_y,
                    'accel_z': sensor_data.gyro_data.accel_z,
                    'battery_level': sensor_data.battery_level,
                    'signal_strength': sensor_data.signal_strength
                }
                writer.writerow(row)
        
        logger.info(f"í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {unified_file.name}")
        
    except Exception as e:
        logger.error(f"í†µí•© ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")


@app.get("/stats", response_model=ServerStats)
async def get_server_stats():
    """ì„œë²„ í†µê³„ ì¡°íšŒ"""
    try:
        # íŒŒì¼ í†µê³„
        raw_files = list(data_manager.directories['raw'].rglob("*.csv"))
        unified_files = list(data_manager.directories['unified'].glob("*.csv"))
        
        # í´ë˜ìŠ¤ ëª©ë¡
        classes_collected = set()
        for file in unified_files:
            if "_unified_" in file.name:
                class_label = file.name.split("_unified_")[0]
                classes_collected.add(class_label)
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
        disk_usage = {}
        for name, path in data_manager.directories.items():
            if path.exists():
                size = sum(f.stat().st_size for f in path.rglob("*") if f.is_file())
                disk_usage[name] = size
        
        return ServerStats(
            total_sessions=len(list(data_manager.directories['metadata'].glob("session_*.json"))),
            total_samples=len(raw_files),
            classes_collected=list(classes_collected),
            disk_usage=disk_usage,
            uptime="running"
        )
        
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/experiments/list")
async def list_experiments():
    """ì‹¤í—˜ ëª©ë¡ ì¡°íšŒ"""
    try:
        unified_files = list(data_manager.directories['unified'].glob("*_unified_*.csv"))
        experiments = []
        
        for file in unified_files:
            if "_unified_" in file.name:
                parts = file.name.replace(".csv", "").split("_unified_")
                class_label = parts[0]
                timestamp = parts[1]
                
                # íŒŒì¼ ì •ë³´
                stat = file.stat()
                experiments.append({
                    'class_label': class_label,
                    'timestamp': timestamp,
                    'file_size': stat.st_size,
                    'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'file_path': str(file.relative_to(Path.cwd()))
                })
        
        return {'experiments': experiments}
        
    except Exception as e:
        logger.error(f"ì‹¤í—˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/download/{file_type}/{filename}")
async def download_file(file_type: str, filename: str):
    """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        if file_type not in data_manager.directories:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ íƒ€ì…")
        
        file_path = data_manager.directories[file_type] / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='application/octet-stream'
        )
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ===== ìƒˆë¡œìš´ í†µí•© API ì—”ë“œí¬ì¸íŠ¸ =====

@app.post("/inference/predict")
async def predict_ksl(sensor_data_list: List[SensorData]):
    """
    ì‹¤ì‹œê°„ KSL ì˜ˆì¸¡ (KLP-SignGlove í†µí•© ê¸°ëŠ¥)
    """
    try:
        if not sensor_data_list:
            raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ì „ì²˜ë¦¬
        processed_data = preprocessor.preprocess_sensor_sequence(
            sensor_data_list,
            apply_filter=True,
            apply_normalization=True,
            apply_smoothing=True
        )
        
        # ì¶”ë¡  (MockModel ì‚¬ìš©)
        if hasattr(inference_engine.model, 'predict'):
            predicted_class, confidence = inference_engine.model.predict(processed_data)
        else:
            predicted_class, confidence = "ã„±", 0.75  # ê¸°ë³¸ê°’
        
        # ì•ˆì •ì„± ì²´í¬
        is_stable, stability_score = inference_engine.stability_checker.add_prediction(
            predicted_class, confidence
        )
        
        result = {
            "predicted_class": predicted_class,
            "confidence": confidence,
            "is_stable": is_stable,
            "stability_score": stability_score,
            "timestamp": datetime.now().isoformat(),
            "sample_count": len(sensor_data_list)
        }
        
        logger.info(f"KSL ì˜ˆì¸¡: {predicted_class} (ì‹ ë¢°ë„: {confidence:.2f}, ì•ˆì •ì„±: {is_stable})")
        return result
        
    except Exception as e:
        logger.error(f"KSL ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/inference/stream")
async def stream_inference(sensor_data: SensorData):
    """
    ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶”ë¡  (562 FPS ì„±ëŠ¥)
    """
    try:
        # ì¶”ë¡  ì—”ì§„ ì‹œì‘ (ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì€ ê²½ìš°)
        if not inference_engine.is_running:
            inference_engine.start()
        
        # ì„¼ì„œ ë°ì´í„° ì¶”ê°€
        success = inference_engine.add_sensor_data(sensor_data)
        
        if not success:
            raise HTTPException(status_code=429, detail="ì²˜ë¦¬ íê°€ ê°€ë“ì°¸")
        
        # í˜„ì¬ ì•ˆì •ëœ ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜
        stable_prediction = inference_engine.get_stable_prediction()
        
        result = {
            "queued": True,
            "queue_size": inference_engine.sensor_queue.qsize(),
            "stable_prediction": stable_prediction,
            "timestamp": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/inference/metrics")
async def get_inference_metrics():
    """
    ì¶”ë¡  ì—”ì§„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ
    """
    try:
        metrics = inference_engine.get_performance_metrics()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ì— ë©”íŠ¸ë¦­ ê¸°ë¡
        capture_inference_metrics(
            fps=metrics.fps,
            latency_ms=metrics.avg_latency_ms,
            stable_predictions=metrics.stable_predictions,
            total_predictions=metrics.total_predictions
        )
        
        return {
            "fps": metrics.fps,
            "avg_latency_ms": metrics.avg_latency_ms,
            "total_predictions": metrics.total_predictions,
            "stable_predictions": metrics.stable_predictions,
            "accuracy_rate": metrics.accuracy_rate,
            "uptime_seconds": metrics.uptime_seconds,
            "is_running": inference_engine.is_running,
            "queue_size": inference_engine.sensor_queue.qsize()
        }
        
    except Exception as e:
        logger.error(f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/tts/speak")
async def speak_text(text: str, confidence: float = 1.0):
    """
    TTS ìŒì„± ì¶œë ¥ (í•œêµ­ì–´ KSL ì§€ì›)
    """
    try:
        if not text.strip():
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # TTS ì—”ì§„ ì‹œì‘ (ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì€ ê²½ìš°)
        if not tts_engine.is_running:
            tts_engine.start()
        
        # ë¹„ë™ê¸° ìŒì„± ì¶œë ¥
        speak_ksl_async(text, confidence)
        
        # KSL â†’ ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼ ë°˜í™˜
        speech_text = tts_engine.convert_ksl_to_speech(text)
        
        result = {
            "original_text": text,
            "speech_text": speech_text,
            "confidence": confidence,
            "queued": True,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"TTS ìš”ì²­: {text} â†’ {speech_text}")
        return result
        
    except Exception as e:
        logger.error(f"TTS ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/tts/test")
async def test_tts():
    """TTS í…ŒìŠ¤íŠ¸"""
    try:
        # TTS ì—”ì§„ ì‹œì‘
        if not tts_engine.is_running:
            tts_engine.start()
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        success = tts_engine.test_speech()
        
        return {
            "success": success,
            "platform": tts_engine.platform,
            "voice": tts_engine.config.voice,
            "enabled": tts_engine.config.enabled,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"TTS í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/preprocessing/process")
async def preprocess_data(sensor_data_list: List[SensorData], 
                         apply_filter: bool = True,
                         apply_normalization: bool = True,
                         apply_smoothing: bool = True,
                         create_windows: bool = False):
    """
    ì„¼ì„œ ë°ì´í„° ì „ì²˜ë¦¬ (KLP-SignGlove ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸)
    """
    try:
        if not sensor_data_list:
            raise HTTPException(status_code=400, detail="ì„¼ì„œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        processed_data = preprocessor.preprocess_sensor_sequence(
            sensor_data_list,
            apply_filter=apply_filter,
            apply_normalization=apply_normalization,
            apply_smoothing=apply_smoothing,
            create_windows=create_windows
        )
        
        # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ìš©)
        result = {
            "flex_data": processed_data['flex'].tolist(),
            "gyro_data": processed_data['gyro'].tolist(), 
            "accel_data": processed_data['accel'].tolist(),
            "sample_count": len(sensor_data_list),
            "processing_config": {
                "filter_applied": apply_filter,
                "normalization_applied": apply_normalization,
                "smoothing_applied": apply_smoothing,
                "windows_created": create_windows
            },
            "preprocessor_stats": preprocessor.get_preprocessing_stats(),
            "timestamp": datetime.now().isoformat()
        }
        
        if 'windowed' in processed_data:
            result["windowed_data"] = processed_data['windowed'].tolist()
            result["window_shape"] = processed_data['windowed'].shape
        
        logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {len(sensor_data_list)}ê°œ ìƒ˜í”Œ")
        return result
        
    except Exception as e:
        logger.error(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/performance/current")
async def get_current_performance():
    """í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        metrics = performance_monitor.get_current_metrics()
        return metrics
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/performance/summary")
async def get_performance_summary(duration_minutes: int = 60):
    """ì„±ëŠ¥ ìš”ì•½ í†µê³„ ì¡°íšŒ"""
    try:
        summary = performance_monitor.get_performance_summary(duration_minutes)
        return summary
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/performance/start")
async def start_performance_monitoring():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    try:
        performance_monitor.start_monitoring()
        return {"status": "started", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/performance/stop")
async def stop_performance_monitoring():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    try:
        performance_monitor.stop_monitoring()
        return {"status": "stopped", "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/performance/report")
async def export_performance_report():
    """ì„±ëŠ¥ ë³´ê³ ì„œ ë‚´ë³´ë‚´ê¸°"""
    try:
        report_file = performance_monitor.export_performance_report()
        return {
            "report_file": str(report_file),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ì„œë²„ ì‹œì‘ í•¨ìˆ˜
def start_server(host: str = "0.0.0.0", port: int = 8000):
    """ì„œë²„ ì‹œì‘"""
    print("=" * 60)
    print("ğŸš€ SignGlove í†µí•© ë°ì´í„° ìˆ˜ì§‘ ì„œë²„ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“¡ ì„œë²„ ì£¼ì†Œ: http://{host}:{port}")
    print(f"ğŸ“Š API ë¬¸ì„œ: http://{host}:{port}/docs")
    print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {data_manager.data_root}")
    print("")
    
    uvicorn.run(app, host=host, port=port, log_level="info")


if __name__ == "__main__":
    start_server() 